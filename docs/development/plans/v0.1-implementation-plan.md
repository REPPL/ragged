# ragged v0.1 Implementation Plan

**Version**: 0.1.0
**Status**: In Progress
**Start Date**: 2025-11-09
**Target Completion**: ~6 weeks
**Last Updated**: 2025-11-09

---

## Executive Summary

This document outlines the comprehensive implementation plan for ragged version 0.1, the first working release of our privacy-first local RAG system. The plan prioritises quality, security, and best practices over speed, following state-of-the-art 2025 RAG architecture patterns.

### Key Decisions

- **Development Approach**: Hybrid (local development â†’ Docker integration)
- **Testing Strategy**: Hybrid TDD (tests-first for core logic, tests-after for integration)
- **Embedding Models**: Dual support (sentence-transformers + Ollama, configurable)
- **Timeline**: No trade-offs on quality; take the time needed (~6 weeks estimated)

### Success Criteria

âœ… All document formats (PDF, TXT, MD, HTML) working
âœ… Both embedding models supported and configurable
âœ… 60-70% test coverage achieved
âœ… End-to-end pipeline functional
âœ… CLI commands intuitive and documented
âœ… Security audit passed
âœ… Performance targets met (<5s queries)
âœ… Docker setup working
âœ… Documentation complete

---

## Phase 1: Foundation & Development Environment (Days 1-2)

### 1.1 Package Structure

Create modern Python package with proper organisation:

```
src/
â”œâ”€â”€ __init__.py              # Version info
â”œâ”€â”€ main.py                  # CLI entry point (Phase 8)
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py          # Pydantic-based configuration
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loaders.py          # Document loaders
â”‚   â””â”€â”€ parsers.py          # Format-specific parsers
â”œâ”€â”€ chunking/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ splitters.py        # Text chunking
â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py             # Abstract interface
â”‚   â”œâ”€â”€ sentence_transformer.py
â”‚   â””â”€â”€ ollama_embedder.py
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ vector_store.py     # ChromaDB interface
â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ retriever.py        # Query & retrieval
â”œâ”€â”€ generation/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ollama_client.py
â”‚   â””â”€â”€ prompts.py
â””â”€â”€ utils/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ logging.py
    â””â”€â”€ security.py
```

**Deliverables**:
- [ ] All package directories created
- [ ] `pyproject.toml` with modern packaging configuration
- [ ] Proper `__init__.py` files with exports

### 1.2 Configuration System (TDD)

**Tests First**:
- Default settings loading
- .env file parsing
- Environment variable overrides
- Model selection (sentence-transformers vs Ollama)
- Validation (chunk size, overlap, k, file size)
- Data directory creation
- Singleton pattern for get_settings()

**Implementation**:
- Pydantic BaseSettings for type-safe config
- Support for both embedding models
- Validation rules
- Automatic data directory creation

**Files**:
- `src/config/settings.py`
- `tests/config/test_settings.py`

**Configuration Options**:
```python
# Environment
RAGGED_ENVIRONMENT=development|production|testing

# Services
RAGGED_OLLAMA_URL=http://localhost:11434
RAGGED_CHROMA_URL=http://localhost:8001

# Embedding Model Selection
RAGGED_EMBEDDING_MODEL=sentence-transformers|ollama
RAGGED_EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2|nomic-embed-text
RAGGED_EMBEDDING_DIMENSIONS=384|768 (auto-set)

# Chunking
RAGGED_CHUNK_SIZE=500
RAGGED_CHUNK_OVERLAP=100

# Retrieval
RAGGED_RETRIEVAL_K=5

# Generation
RAGGED_LLM_MODEL=llama3.2:3b

# Storage
RAGGED_DATA_DIR=~/.ragged

# Limits
RAGGED_MAX_FILE_SIZE_MB=100

# Logging
RAGGED_LOG_LEVEL=INFO|DEBUG|WARNING|ERROR|CRITICAL
```

### 1.3 Logging Infrastructure

**Implementation**:
- Structured JSON logging using python-json-logger
- Console and file output
- Log rotation
- Privacy-safe logging (no PII)
- Performance logging helpers

**Files**:
- `src/utils/logging.py`
- `tests/utils/test_logging.py`

### 1.4 Development Tooling

**Tools to Configure**:
- **black**: Code formatting (line-length=100)
- **ruff**: Fast linting with security checks (S prefix)
- **mypy**: Type checking with strict mode
- **pytest**: Test runner with coverage
- **pre-commit**: Git hooks for quality

**Files**:
- `.pre-commit-config.yaml`
- Configuration in `pyproject.toml`

**Pre-commit Hooks**:
```yaml
- black (formatting)
- ruff (linting)
- mypy (type checking)
- trailing-whitespace
- end-of-file-fixer
- check-yaml
- check-merge-conflict
```

---

## Phase 2: Document Ingestion Pipeline (Days 3-6)

### 2.1 Document Models

**Pydantic Models**:
```python
class DocumentMetadata:
    file_path: Path
    file_size: int
    file_hash: str  # SHA256
    created_at: datetime
    modified_at: datetime
    format: str
    title: Optional[str]
    author: Optional[str]

class Chunk:
    chunk_id: str
    text: str
    tokens: int
    position: int  # Position in document
    document_id: str
    metadata: ChunkMetadata

class Document:
    document_id: str
    content: str
    metadata: DocumentMetadata
    chunks: List[Chunk]
```

### 2.2 Document Loaders (TDD)

**PDF Loader** (`PyMuPDF4LLM`):
- Preserve document structure
- Handle scanned PDFs
- Extract metadata (title, author, dates)
- Tests: various PDF types, malformed PDFs, scanned documents

**TXT Loader**:
- UTF-8 with fallback encodings (chardet)
- Preserve line breaks and formatting
- Tests: various encodings, special characters

**Markdown Loader**:
- Direct text reading
- Metadata from frontmatter (if present)
- Tests: standard markdown, with frontmatter, edge cases

**HTML Loader** (`Trafilatura`):
- Content extraction (removes navigation, ads, etc.)
- Preserve structure
- Metadata extraction
- Tests: various HTML structures, malformed HTML

**Security Considerations**:
- Path traversal prevention (validate file paths)
- File size limits (configurable, default 100MB)
- Malicious PDF detection (basic checks)
- Safe HTML parsing (prevent XSS)
- MIME type validation

**Files**:
- `src/ingestion/loaders.py`
- `src/ingestion/parsers.py`
- `tests/ingestion/test_loaders.py`
- `tests/ingestion/test_parsers.py`

### 2.3 Metadata Extraction

**For All Formats**:
- File system metadata (size, dates, path)
- SHA256 hash for deduplication
- MIME type detection

**Format-Specific**:
- PDF: title, author, creation date, page count
- HTML: title, description, URL (if web content)
- Markdown: frontmatter metadata

---

## Phase 3: Chunking System (Days 7-10)

### 3.1 Token Counting (TDD)

**Implementation**:
- Use tiktoken for accurate token counting
- Model-aware tokenization
- Caching for performance

**Files**:
- `src/chunking/token_counter.py`
- `tests/chunking/test_token_counter.py`

### 3.2 RecursiveCharacterTextSplitter (TDD)

**Algorithm**:
1. Try splitting on `\n\n` (paragraph breaks)
2. If chunks too large, split on `\n` (line breaks)
3. If still too large, split on `. ` (sentences)
4. If still too large, split on ` ` (words)
5. Last resort: split by character count

**Parameters**:
- `chunk_size`: 500 tokens (configurable)
- `chunk_overlap`: 100 tokens (configurable)
- Smart boundary detection (avoid mid-sentence splits)

**Tests**:
- Chunk size limits respected
- Overlap correctness
- Boundary preservation
- Edge cases (very short/long documents)
- Performance with large documents

**Files**:
- `src/chunking/splitters.py`
- `tests/chunking/test_splitters.py`

### 3.3 Chunk Metadata

**Metadata per Chunk**:
```python
class ChunkMetadata:
    document_id: str
    document_path: Path
    chunk_position: int  # 0-indexed position
    total_chunks: int
    overlap_with_previous: int  # characters
    overlap_with_next: int
```

### 3.4 Chunking Quality Evaluation

**Manual Evaluation**:
- Visual inspection of chunks
- Boundary quality assessment
- Semantic coherence check
- Edge case validation

---

## Phase 4: Embeddings System (Days 11-14)

### 4.1 Embedding Interface (TDD)

**Abstract Base Class**:
```python
class BaseEmbedder(ABC):
    @abstractmethod
    def embed_text(self, text: str) -> np.ndarray:
        """Embed single text."""

    @abstractmethod
    def embed_batch(self, texts: List[str]) -> np.ndarray:
        """Embed multiple texts efficiently."""

    @property
    @abstractmethod
    def dimensions(self) -> int:
        """Return embedding dimensions."""
```

**Tests**: Interface compliance for all implementations

### 4.2 SentenceTransformer Embedder (TDD)

**Implementation**:
- Model: `all-MiniLM-L6-v2` (384 dimensions)
- Batch processing for efficiency
- Device detection (CPU/CUDA/MPS)
- Model caching

**Optimisation**:
- Batch size: 32 (configurable)
- GPU acceleration when available
- Memory-efficient processing

**Tests**:
- Embedding shape correctness
- Batch vs single consistency
- Device detection
- Error handling

**Files**:
- `src/embeddings/sentence_transformer.py`
- `tests/embeddings/test_sentence_transformer.py`

### 4.3 Ollama Embedder (TDD)

**Implementation**:
- Model: `nomic-embed-text` (768 dimensions)
- API integration with ollama library
- Retry logic with exponential backoff
- Timeout handling

**Tests**:
- API integration
- Error handling (service down, timeout)
- Retry logic
- Batch processing

**Files**:
- `src/embeddings/ollama_embedder.py`
- `tests/embeddings/test_ollama_embedder.py`

### 4.4 Embedder Factory

**Implementation**:
- Factory pattern for model selection
- Configuration-based instantiation
- Lazy loading

**Files**:
- `src/embeddings/factory.py`
- `tests/embeddings/test_factory.py`

**Security**:
- API request validation
- No sensitive data in embeddings
- Secure API key handling

---

## Phase 5: Vector Storage (Days 15-17)

### 5.1 ChromaDB Client Wrapper (TDD)

**Implementation**:
- Connection management
- Collection CRUD operations
- Health checks
- Auto-reconnection logic

**Collections Structure**:
```python
# v0.1: Single collection
collection_name = "ragged_documents"

# Metadata stored:
{
    "document_id": str,
    "document_path": str,
    "chunk_position": int,
    "chunk_text": str,  # Full text for retrieval
    "file_format": str,
    "created_at": str (ISO),
}
```

**Tests**:
- Connection establishment
- Collection creation/deletion
- Health checks
- Error handling (service down)
- Auto-reconnection

**Files**:
- `src/storage/vector_store.py`
- `tests/storage/test_vector_store.py`

### 5.2 Vector Operations (TDD)

**Add Documents**:
- Batch upsert for efficiency
- Metadata storage
- Duplicate handling

**Query**:
- Vector similarity search
- Top-k retrieval
- Metadata filtering
- Score threshold filtering (optional)

**Delete**:
- By document ID
- By metadata filter
- Bulk delete

**Tests**:
- Add single/batch
- Query correctness
- Ranking validation
- Delete operations
- Edge cases (empty collection, no matches)

### 5.3 Persistence Validation

**Tests**:
- Data survives container restarts
- Backup and restore
- Data integrity

**Files**:
- `tests/storage/test_persistence.py` (marked as integration test)

**Security**:
- Input sanitization for metadata
- Prevent injection attacks
- Validate vector dimensions

---

## Phase 6: Retrieval System (Days 18-20)

### 6.1 Query Processing (TDD)

**Pipeline**:
1. Embed query using configured embedder
2. Search vector store
3. Retrieve top-k chunks
4. Deduplicate if needed
5. Format with metadata

**Implementation**:
```python
class Retriever:
    def retrieve(
        self,
        query: str,
        k: int = 5,
        filter_metadata: Optional[Dict] = None
    ) -> List[RetrievedChunk]:
        ...
```

**Tests**:
- Query embedding
- Top-k retrieval
- Metadata filtering
- Edge cases (no matches, k > total documents)

**Files**:
- `src/retrieval/retriever.py`
- `tests/retrieval/test_retriever.py`

### 6.2 Result Formatting

**Retrieved Chunk Format**:
```python
class RetrievedChunk:
    text: str
    score: float  # Similarity score
    document_id: str
    document_path: Path
    chunk_position: int
    metadata: Dict[str, Any]
```

**Deduplication**:
- If multiple chunks from same document, optionally merge
- Preserve document context

**Tests**:
- Formatting correctness
- Deduplication logic
- Score ordering

### 6.3 Retrieval Evaluation

**Manual Test Set**:
- 20+ questions across different document types
- Manual relevance assessment
- Metrics:
  - Relevance@k (target: >70%)
  - MRR (Mean Reciprocal Rank)
  - Precision@k

**Files**:
- `tests/retrieval/test_evaluation.py`
- `tests/data/evaluation_questions.json`

**Security**:
- Query sanitization
- Prevent prompt injection in queries

---

## Phase 7: Generation System (Days 21-23)

### 7.1 Ollama Client (Integration Tests)

**Implementation**:
- Chat completions API
- Streaming support (for future CLI improvements)
- Timeout handling (30s default)
- Retry logic
- Error handling

**Tests**:
- API integration
- Streaming responses
- Timeout handling
- Error scenarios (model not found, service down)

**Files**:
- `src/generation/ollama_client.py`
- `tests/generation/test_ollama_client.py`

### 7.2 Prompt Engineering

**RAG Prompt Template**:
```
You are a helpful assistant that answers questions based on the provided context.

Context:
{context}

Question: {question}

Instructions:
1. Answer the question using ONLY information from the context above
2. If the context doesn't contain enough information, say "I don't have enough information to answer that"
3. Include citations in your answer using [Source: filename] format
4. Be concise and accurate

Answer:
```

**Few-Shot Examples** (for complex queries):
- Example question + context + ideal answer
- Helps with citation formatting
- Improves hallucination prevention

**Tests**:
- Prompt formatting
- Context injection
- Citation format
- Edge cases (long context, empty context)

**Files**:
- `src/generation/prompts.py`
- `tests/generation/test_prompts.py`

### 7.3 Response Parsing

**Parse Response**:
```python
class GeneratedResponse:
    answer: str
    citations: List[str]  # Extracted source filenames
    confidence: Optional[float]  # For future versions
```

**Tests**:
- Citation extraction
- Answer formatting
- Edge cases (no citations, malformed response)

**Files**:
- `src/generation/response_parser.py`
- `tests/generation/test_response_parser.py`

### 7.4 Model Selection

**Default Models**:
- `llama3.2:3b` (fast, good quality)
- Configurable via `RAGGED_LLM_MODEL`

**Fallback Logic** (future):
- If model not available, suggest alternatives
- Model availability check on startup

**Security**:
- Prompt injection prevention
- Output sanitization
- Token limits to prevent abuse

---

## Phase 8: CLI Interface (Days 24-26)

### 8.1 Click-Based Commands

**Commands**:
```bash
ragged add <file>           # Ingest document
ragged query "<question>"   # Ask question
ragged list                 # List indexed documents
ragged clear                # Clear database
ragged config               # Show configuration
ragged config set <key> <value>  # Update configuration
ragged health               # Check service health
```

**Implementation**:
- Click for command parsing
- Rich for output formatting (progress bars, tables)
- Colored output for better UX
- Progress indicators for long operations

**Files**:
- `src/main.py`
- `tests/cli/test_commands.py`

### 8.2 Command Implementation

**`ragged add`**:
- Validate file exists and size
- Show progress: parsing â†’ chunking â†’ embedding â†’ storing
- Report success with document ID
- Handle errors gracefully

**`ragged query`**:
- Embed query
- Retrieve chunks
- Generate answer
- Display with citations
- Show processing time

**`ragged list`**:
- Show all indexed documents
- Display as table: ID | Path | Format | Size | Chunks | Date

**`ragged clear`**:
- Confirm before clearing (unless --force)
- Clear vector database
- Report success

**`ragged config`**:
- Show current configuration
- Allow runtime updates (write to .env)

**`ragged health`**:
- Check Ollama connectivity
- Check ChromaDB connectivity
- Check embedding model availability
- Report status with colored indicators

**Tests**:
- Each command with valid inputs
- Error handling
- Edge cases
- Output formatting

### 8.3 Error Handling

**User-Friendly Messages**:
- Clear error descriptions
- Helpful suggestions
- Examples of correct usage

**Common Errors**:
- File not found â†’ "File 'x' not found. Check the path."
- Ollama down â†’ "Cannot connect to Ollama at {url}. Is it running? Try: ollama serve"
- ChromaDB down â†’ "Cannot connect to ChromaDB. Start with: docker-compose up -d"
- Unsupported format â†’ "Format '.xyz' not supported. Supported: PDF, TXT, MD, HTML"

**Security**:
- Input validation (paths, commands)
- Path traversal prevention
- Command injection prevention

---

## Phase 9: End-to-End Integration (Days 27-29)

### 9.1 Integration Tests

**Full Pipeline Tests**:
```python
def test_end_to_end_pdf():
    # Ingest PDF
    # Query it
    # Verify answer quality

def test_end_to_end_multiple_documents():
    # Ingest 3+ documents
    # Query spanning multiple sources
    # Verify citations from multiple sources
```

**Scenarios**:
- Single document ingestion and query
- Multiple documents
- Cross-format queries (PDF + TXT + MD)
- Error recovery (service restart mid-operation)

**Files**:
- `tests/integration/test_end_to_end.py`

### 9.2 Quality Validation

**Test Documents** (10+ diverse):
- Academic papers (PDF)
- Technical documentation (MD)
- News articles (HTML)
- Personal notes (TXT)

**Test Questions** (20+):
- Factual questions
- Questions requiring multiple sources
- Questions with no answer in corpus
- Complex multi-part questions

**Metrics**:
- Retrieval relevance: >70% target
- Answer faithfulness: >80% target
- Query latency: <5s target
- False positive rate (irrelevant retrievals)

**Manual Evaluation**:
- Review generated answers
- Assess citation accuracy
- Check for hallucinations

### 9.3 Performance Validation

**Benchmarks**:
- Ingestion time (per document, per format)
- Embedding time (batch of 100 chunks)
- Query time (end-to-end)
- Memory usage (with 100+ documents)

**Optimisation** (if needed):
- Batch size tuning
- Caching strategies
- Concurrent processing

**Files**:
- `tests/performance/test_benchmarks.py`

**Security**:
- Full integration security audit
- Test with potentially malicious inputs
- Verify all validation layers work together

---

## Phase 10: Docker Integration (Days 30-32)

### 10.1 Fix Dockerfile

**Current Issue**: Cannot import `src.main`

**Solution**:
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Copy and install Python dependencies
COPY requirements-dev.txt .
RUN pip install --no-cache-dir -r requirements-dev.txt

# Copy source code
COPY src/ /app/src/
COPY pyproject.toml /app/

# Install package in editable mode
RUN pip install -e .

# Create non-root user
RUN useradd -m -u 1000 ragged && chown -R ragged:ragged /app
USER ragged

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD python -c "import httpx; httpx.get('http://localhost:8000/health').raise_for_status()"

CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Tests**:
- Docker build succeeds
- Container starts without errors
- Health check passes

### 10.2 Docker Compose Refinement

**Updates**:
- Add volume mounts for development
- Pass all environment variables
- Proper health checks
- Network configuration

**docker-compose.yml**:
```yaml
version: '3.8'

services:
  chromadb:
    image: chromadb/chroma:latest
    container_name: ragged-chromadb
    ports:
      - "8001:8000"
    volumes:
      - chroma-data:/chroma/chroma
    environment:
      IS_PERSISTENT: "TRUE"
      ANONYMIZED_TELEMETRY: "FALSE"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ragged-network

  ragged-app:
    build: .
    container_name: ragged-app
    ports:
      - "8000:8000"
    volumes:
      - ./src:/app/src  # Development mount
      - ~/.ragged:/home/ragged/.ragged
    environment:
      RAGGED_CHROMA_URL: http://chromadb:8000
      RAGGED_OLLAMA_URL: http://host.docker.internal:11434
      RAGGED_ENVIRONMENT: development
    depends_on:
      chromadb:
        condition: service_healthy
    networks:
      - ragged-network

volumes:
  chroma-data:

networks:
  ragged-network:
    driver: bridge
```

### 10.3 Container Testing

**Test in Container**:
- Run full test suite inside container
- Verify ChromaDB connectivity
- Verify Ollama connectivity (to host)
- End-to-end test in containerized environment

**Files**:
- `tests/integration/test_docker.py`

**Security**:
- Non-root user in container
- Minimal base image (python:3.11-slim)
- No secrets in image
- Volume permissions correct

---

## Phase 11: Documentation (Days 33-35)

### 11.1 User Documentation

**README.md** (update):
- Project description
- Features
- Installation (local + Docker)
- Quick start guide
- Links to detailed docs

**docs/user-guide/**:
- `installation.md`: Detailed setup instructions
- `quick-start.md`: Tutorial with examples
- `cli-reference.md`: All commands documented
- `configuration.md`: All config options
- `troubleshooting.md`: Common issues and solutions

**Examples**:
- Example documents in `examples/documents/`
- Example queries in `examples/queries.md`

### 11.2 Developer Documentation

**docs/developer/**:
- `architecture.md`: System architecture overview
- `contributing.md`: How to contribute
- `testing.md`: Running tests, writing tests
- `code-standards.md`: Coding conventions

**API Documentation**:
- Comprehensive docstrings for all public APIs
- Type hints everywhere
- Examples in docstrings

**Inline Documentation**:
- Comments for complex logic
- Explanations of design decisions

### 11.3 Version Documentation

**CHANGELOG.md**:
```markdown
# Changelog

## [0.1.0] - 2025-11-XX

### Added
- Document ingestion (PDF, TXT, MD, HTML)
- Configurable embedding models (sentence-transformers + Ollama)
- ChromaDB vector storage
- Ollama LLM integration
- CLI interface with 6 commands
- Comprehensive test suite (60-70% coverage)
- Docker containerization
- Complete documentation
```

**docs/versions/v0.1.md**:
- Detailed version notes
- What's included
- Known limitations
- Upgrade path (future)

---

## Phase 12: Security Audit & Code Review (Days 36-37)

### 12.1 Security Audit (use codebase-security-auditor agent)

**Checklist**:
- [ ] OWASP Top 10 review
- [ ] Input validation (all user inputs)
- [ ] Path traversal prevention
- [ ] SQL/NoSQL injection prevention
- [ ] Command injection prevention
- [ ] XSS prevention (HTML parsing)
- [ ] File upload security
- [ ] API authentication (not needed for v0.1, but reviewed)
- [ ] Secrets management (no hardcoded secrets)
- [ ] Dependency vulnerabilities (pip-audit)
- [ ] Privacy compliance (no data leakage)

**Tools**:
- `bandit` (security linting)
- `pip-audit` (dependency check)
- `safety` (known vulnerabilities)
- Manual code review with codebase-security-auditor agent

**Fixes**:
- Address all high/critical issues
- Document medium/low issues for future versions

### 12.2 Code Quality Review

**Static Analysis**:
- `mypy --strict` passes
- `ruff` passes with no errors
- `black --check` passes
- Code complexity analysis (McCabe)

**Manual Review**:
- Code readability
- DRY principle adherence
- Proper error handling
- Type hint coverage
- Documentation completeness

**Refactoring**:
- Extract complex functions
- Reduce code duplication
- Improve naming
- Add missing type hints

### 12.3 Performance Profiling

**Tools**:
- `cProfile` for hotspot identification
- `memory_profiler` for memory analysis
- `py-spy` for production profiling

**Metrics**:
- Identify bottlenecks
- Check for memory leaks
- Validate performance targets

**Optimisations** (if needed):
- Cache frequently used data
- Optimise batch sizes
- Reduce redundant operations

---

## Phase 13: Testing & Coverage (Days 38-40)

### 13.1 Test Coverage Validation

**Target**: 60-70% overall, 90%+ for core logic

**Run Coverage**:
```bash
pytest --cov=src --cov-report=html --cov-report=term-missing
```

**Review**:
- Identify uncovered code
- Write tests for critical uncovered paths
- Document acceptable gaps (e.g., error handlers for rare conditions)

**Coverage by Module**:
- config: 90%+
- ingestion: 80%+
- chunking: 90%+
- embeddings: 85%+
- storage: 85%+
- retrieval: 90%+
- generation: 75%+
- CLI: 70%+

### 13.2 Manual Testing

**Cross-Platform**:
- Test on macOS (primary)
- Test on Linux (Ubuntu in Docker)
- Document any platform-specific issues

**Real-World Scenarios**:
- Ingest user's actual documents
- Ask realistic questions
- Verify answer quality

**Usability Testing**:
- Is CLI intuitive?
- Are error messages helpful?
- Is performance acceptable?

### 13.3 Test Organisation

**Test Markers**:
```python
@pytest.mark.unit         # Fast, isolated
@pytest.mark.integration  # Multiple components
@pytest.mark.e2e          # Full system
@pytest.mark.slow         # Long-running
```

**Running Tests**:
```bash
# All tests
pytest

# Unit only (fast)
pytest -m "unit"

# Without slow tests
pytest -m "not slow"

# With coverage
pytest --cov=src
```

---

## Phase 14: Git Commit & Release (Day 41)

### 14.1 Final Code Review

**Pre-Commit Checklist**:
- [ ] All tests pass
- [ ] Coverage targets met
- [ ] Security audit passed
- [ ] Documentation complete
- [ ] British English in all docs
- [ ] Version numbers correct (0.1.0)
- [ ] No debug code or print statements
- [ ] No TODO comments (or documented in issues)

**Code Quality**:
- Run all linters one final time
- Fix any remaining issues
- Ensure code is clean and professional

### 14.2 Git Commit (use git-documentation-committer agent)

**Process**:
1. Use `git-documentation-committer` agent
2. Agent will:
   - Review all changes
   - Update documentation as needed
   - Generate comprehensive commit message
   - Create commit with co-authorship

**Commit Message Format**:
```
feat: Implement ragged v0.1.0 - Privacy-first local RAG system

Comprehensive implementation of ragged version 0.1 including:

Core Features:
- Document ingestion (PDF, TXT, MD, HTML)
- Dual embedding model support (sentence-transformers + Ollama)
- ChromaDB vector storage
- Ollama LLM integration
- Full CLI interface (add, query, list, clear, config, health)

Technical Implementation:
- Modern Python packaging with pyproject.toml
- Pydantic-based configuration system
- Structured logging with privacy protection
- Comprehensive test suite (60-70% coverage)
- Docker containerisation
- Security-first design (input validation, path sanitisation)

Quality Assurance:
- 150+ tests across unit/integration/e2e
- Security audit passed (OWASP Top 10)
- Performance validated (<5s queries)
- Type-checked with mypy strict mode
- Linted with ruff (security checks enabled)

Documentation:
- Complete user guide
- Developer documentation
- API documentation
- CLI reference
- Troubleshooting guide

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>
```

**Tag Version**:
```bash
git tag -a v0.1.0 -m "ragged version 0.1.0 - First working release"
```

### 14.3 Release Validation

**Fresh Install Test**:
```bash
# Clone to new directory
git clone /path/to/ragged ragged-test
cd ragged-test

# Install
pip install -e ".[dev]"

# Run tests
pytest

# Build Docker
docker-compose build

# Start services
docker-compose up -d

# Run health check
ragged health
```

**Validation**:
- [ ] Clean install works
- [ ] Tests pass
- [ ] Docker builds and runs
- [ ] CLI commands work
- [ ] Documentation renders correctly

---

## Timeline Summary

| Phase | Days | Deliverables |
|-------|------|--------------|
| 1: Foundation | 1-2 | Package structure, config, logging, tooling |
| 2: Ingestion | 3-6 | Document loaders (PDF, TXT, MD, HTML) |
| 3: Chunking | 7-10 | Token counting, recursive splitter |
| 4: Embeddings | 11-14 | Dual model support, factory |
| 5: Storage | 15-17 | ChromaDB integration, persistence |
| 6: Retrieval | 18-20 | Query processing, evaluation |
| 7: Generation | 21-23 | Ollama client, prompts, parsing |
| 8: CLI | 24-26 | 6 commands, rich output |
| 9: Integration | 27-29 | E2E tests, quality validation |
| 10: Docker | 30-32 | Container fixes, testing |
| 11: Documentation | 33-35 | User & developer docs |
| 12: Security | 36-37 | Security audit, code review |
| 13: Testing | 38-40 | Coverage validation, manual testing |
| 14: Release | 41 | Git commit, tagging, validation |

**Total**: ~41 days (~6 weeks)

---

## Risk Management

### Technical Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Ollama connection issues | Medium | High | Comprehensive error handling, health checks |
| ChromaDB performance | Low | Medium | Performance tests, optimisation if needed |
| Large file memory issues | Medium | Medium | File size limits, streaming where possible |
| Embedding model compatibility | Low | Low | Both models tested thoroughly |

### Schedule Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Feature creep | Medium | High | Strict adherence to v0.1 scope |
| Underestimated complexity | Low | Medium | Extra time built into estimates |
| Blocked by dependencies | Low | Low | Early validation of all dependencies |

---

## Success Metrics

### Functional Metrics
- âœ… All 4 document formats working
- âœ… Both embedding models functional
- âœ… 6 CLI commands operational
- âœ… End-to-end pipeline functional

### Quality Metrics
- âœ… 60-70% test coverage achieved
- âœ… 90%+ coverage on core logic
- âœ… All security checks passed
- âœ… Type checking passes (mypy strict)
- âœ… Linting passes (ruff with security)

### Performance Metrics
- âœ… Query latency < 5 seconds
- âœ… Ingestion works for files up to 100MB
- âœ… Supports 100+ documents
- âœ… Retrieval relevance > 70%
- âœ… Answer faithfulness > 80%

### Documentation Metrics
- âœ… User guide complete
- âœ… Developer docs complete
- âœ… All public APIs documented
- âœ… Examples provided

---

## Post-v0.1 Considerations

### Known Limitations (Documented)
- Single collection only
- No hybrid retrieval
- No reranking
- No web UI
- Basic chunking strategy
- No RAGAS evaluation
- No personal memory
- No multi-user support

### Planned for v0.2
- Document normalisation pipeline
- Duplicate detection (SHA256 + MinHash)
- Hybrid retrieval (BM25 + vector)
- Cross-encoder reranking
- Basic Gradio web UI
- RAGAS evaluation framework

---

## Appendix

### Development Setup

**Prerequisites**:
- Python 3.10+
- Docker Desktop
- Ollama

**Installation**:
```bash
# Clone repository
git clone <repo>
cd ragged

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -e ".[dev]"

# Install pre-commit hooks
pre-commit install

# Start services
docker-compose up -d

# Install Ollama models
ollama pull llama3.2:3b
ollama pull nomic-embed-text
```

### Key Dependencies

**Core**:
- Python 3.10+
- pydantic 2.5+
- chromadb 0.4.18+
- sentence-transformers 2.2.2+
- ollama 0.1+

**Document Processing**:
- PyMuPDF 1.23+
- PyMuPDF4LLM 0.0.1+
- trafilatura 1.6+
- python-docx 1.1+

**Utilities**:
- click 8.1+
- rich 13.7+
- tiktoken 0.5+
- chardet 5.2+

**Development**:
- pytest 7.4+
- black 23.11+
- ruff 0.1.6+
- mypy 1.7+

### Reference Documentation

**Internal**:
- [Architecture Overview](../architecture/README.md)
- [Testing Strategy](../testing-strategy.md)
- [User Stories](../user-stories/README.md)

**External**:
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [Sentence Transformers](https://www.sbert.net/)
- [Ollama Documentation](https://ollama.ai/docs)

---

**Status**: In Progress
**Last Updated**: 2025-11-09
**Next Review**: After Phase 1 completion
