# v0.5.0: Foundation - ColPali + Dual Storage

**Focus:** Establish foundation for multi-modal document understanding

**Hours:** 55-75 hours

**Dependencies:** v0.4.0 (Knowledge graphs and personal memory)

**Status:** Planned

---

## Overview

Version 0.5.0 establishes the foundation for vision-based document understanding by integrating the ColPali model and creating a dual embedding storage architecture. This version combines two critical features (VISION-001 and VISION-002) that form the basis for all subsequent vision capabilities.

**What This Version Delivers:**
- ColPali vision embedder with GPU/MPS/CPU device detection
- 768-dimensional vision embeddings for PDF pages
- Dual text+vision storage schema in ChromaDB
- Migration utilities for upgrading from v0.4.x
- Configurable vision embedding generation via CLI

**Why These Features Together:**
- ColPali provides vision embeddings (VISION-001)
- Dual storage enables storing both text and vision embeddings side-by-side (VISION-002)
- Neither feature is useful without the other
- Combined implementation avoids schema changes in future versions

---

## Features

### VISION-001: ColPali Vision Embedder (30-40 hours)

**Purpose:** Generate vision-based embeddings that capture document layout, diagrams, tables, and visual content.

**Implementation Phases:**

#### Phase 1: Research & Dependencies (6 hours)
- Study ColPali architecture and model documentation
- Add PyTorch, Transformers, Pillow, pdf2image dependencies
- Document GPU requirements (VRAM, compute)
- Test installation on GPU and CPU systems

**Deliverables:**
- Research notes in `docs/development/research/colpali-architecture.md`
- Updated `pyproject.toml` with vision dependencies
- GPU setup guide in `docs/installation.md`

#### Phase 2: Core ColPali Embedder (14-18 hours)
- Implement `ColPaliEmbedder` class (~350 lines)
- Device detection (CUDA > MPS > CPU priority)
- Single page and batch embedding generation
- PDF to image conversion pipeline
- GPU memory monitoring and batch size estimation
- Error handling with CPU fallback on OOM

**Deliverables:**
- `src/embeddings/colpali_embedder.py` (~350 lines)
- Device detection with automatic fallback
- Memory-aware batch processing

#### Phase 3: Integration & Configuration (6-8 hours)
- Add `VisionConfig` to settings
- CLI integration with `--vision` and `--vision-only` flags
- Environment variables for vision configuration

**Deliverables:**
- `src/config/settings.py` (+50 lines VisionConfig)
- `src/cli/commands/add.py` (+30 lines vision flags)

#### Phase 4: Testing (4-6 hours)
- Unit tests for ColPaliEmbedder (~250 lines)
- Integration tests for full PDF pipeline (~150 lines)
- GPU acceleration validation
- CPU fallback verification

**Deliverables:**
- `tests/embeddings/test_colpali_embedder.py` (~250 lines)
- `tests/integration/test_vision_pipeline.py` (~150 lines)

**Success Criteria:**
- [ ] ColPali model loads on CUDA, MPS, and CPU
- [ ] Vision embeddings generated (768-dimensional)
- [ ] GPU detection automatic (CUDA > MPS > CPU)
- [ ] Batch processing 30%+ faster than sequential
- [ ] Memory usage monitored and adaptive batch sizing works
- [ ] CPU fallback functional on GPU OOM
- [ ] 100% test coverage for ColPaliEmbedder

---

### VISION-002: Dual Embedding Storage (25-35 hours)

**Purpose:** Extend vector storage to simultaneously manage text (384-dim) and vision (768-dim) embeddings with shared metadata.

**Implementation Phases:**

#### Phase 1: Schema Extension (6-8 hours)
- Design dual-embedding collection schema
- Implement typed metadata structures (TextMetadata, VisionMetadata)
- Create ID generation utilities (`{doc}_chunk_{n}_text`, `{doc}_page_{n}_vision`)
- Build migration utilities for v0.4 → v0.5 schema upgrade

**Deliverables:**
- `src/storage/schema.py` (~150 lines)
- `src/storage/migration.py` (~200 lines)
- Schema version detection
- Safe migration with dry-run support

#### Phase 2: DualEmbeddingStore Implementation (8-10 hours)
- Implement `DualEmbeddingStore` class (~350 lines)
- Add methods for text and vision embeddings
- Batch storage operations
- Query methods for text-only, vision-only retrieval
- Hybrid query with reciprocal rank fusion (RRF)

**Deliverables:**
- `src/storage/dual_store.py` (~500 lines total)
- Type-safe storage operations
- Query interfaces for all retrieval modes
- RRF-based score fusion for hybrid queries

#### Phase 3: Ingestion Pipeline Integration (6-8 hours)
- Update `DocumentProcessor` for dual embeddings
- Configurable vision embedding generation
- CLI flags: `--vision/--no-vision`, `--gpu-device`
- Configuration options in settings

**Deliverables:**
- Updated `src/ingestion/processor.py` (~100 lines modified)
- Updated `src/cli.py` with vision flags
- Updated `src/config/settings.py` with storage config

#### Phase 4: Testing (4-6 hours)
- Unit tests for schema, DualEmbeddingStore (~200 lines)
- Integration tests for dual storage pipeline (~150 lines)
- Migration test suite
- Hybrid retrieval validation

**Deliverables:**
- `tests/storage/test_dual_store.py` (~200 lines)
- `tests/integration/test_dual_storage_pipeline.py` (~150 lines)

**Success Criteria:**
- [ ] Text embeddings stored with `embedding_type: "text"` metadata
- [ ] Vision embeddings stored with `embedding_type: "vision"` metadata
- [ ] Unique ID generation working correctly
- [ ] Batch storage <100ms per embedding
- [ ] Separate query methods for text/vision/hybrid
- [ ] Hybrid query uses RRF with configurable weights
- [ ] Migration utility converts v0.4 collections safely
- [ ] 90%+ test coverage for storage module

---

## Implementation Checklist

### Session-by-Session Breakdown

**VISION-001 Sessions (30-40 hours):**

- [ ] **Session 1.1** (4h): ColPali architecture research
  - Study ColPali paper and model documentation
  - Identify GPU requirements and constraints
  - Document findings in research notes

- [ ] **Session 1.2** (2h): Dependency setup
  - Add torch, transformers, Pillow, pdf2image to pyproject.toml
  - Document system dependencies (poppler-utils)
  - Test installation on GPU and CPU

- [ ] **Session 2.1** (4h): ColPaliEmbedder class skeleton
  - Implement class structure and initialisation
  - Device detection (_detect_device method)
  - Model loading (_load_model method)

- [ ] **Session 2.2** (4h): Core embedding methods
  - Implement embed_page (single page)
  - Implement embed_batch (multiple pages)
  - Implement embed_document (full PDF)

- [ ] **Session 2.3** (3-4h): PDF processing pipeline
  - Implement _extract_pages_as_images
  - Add batch size estimation
  - GPU memory monitoring utilities

- [ ] **Session 2.4** (3-4h): Error handling & fallbacks
  - Implement embed_with_fallback
  - GPU OOM recovery
  - CPU fallback on errors

- [ ] **Session 3.1** (3-4h): Configuration updates
  - Add VisionConfig to settings.py
  - Environment variable support
  - Configuration validation

- [ ] **Session 3.2** (3-4h): CLI integration
  - Add --vision and --vision-only flags
  - GPU device selection (--gpu-device)
  - Help text and documentation

- [ ] **Session 4.1** (2-3h): Unit tests
  - Device detection tests
  - Embedding generation tests
  - Batch processing tests
  - Error handling tests

- [ ] **Session 4.2** (2-3h): Integration tests
  - Full PDF pipeline test
  - GPU acceleration validation
  - CPU fallback verification

**VISION-002 Sessions (25-35 hours):**

- [ ] **Session 1.1** (3-4h): ChromaDB collection schema
  - Design metadata structures
  - Implement EmbeddingType enum
  - Create ID generation utilities
  - Implement metadata creation functions

- [ ] **Session 1.2** (3-4h): Migration utilities
  - Implement StorageMigration class
  - Schema version detection
  - Migration with dry-run support
  - Batch migration processing

- [ ] **Session 2.1** (4-5h): DualEmbeddingStore class
  - Implement class initialisation
  - Add text embedding storage
  - Add vision embedding storage
  - Batch storage operations
  - Document retrieval and deletion

- [ ] **Session 2.2** (4-5h): Query interface
  - Implement query_text method
  - Implement query_vision method
  - Implement query_hybrid method
  - Implement RRF score fusion
  - Metadata filtering support

- [ ] **Session 3.1** (3-4h): Update document processor
  - Integrate DualEmbeddingStore
  - Dual embedding generation
  - Configurable vision processing
  - Batch processing optimisation

- [ ] **Session 3.2** (3-4h): CLI and configuration updates
  - Update StorageConfig
  - Add CLI flags for dual storage
  - GPU device selection
  - Hybrid retrieval weight configuration

- [ ] **Session 4.1** (2-3h): Unit tests
  - Schema validation tests
  - DualEmbeddingStore operation tests
  - Migration utility tests
  - Dimension validation tests

- [ ] **Session 4.2** (2-3h): Integration tests
  - End-to-end dual ingestion test
  - Migration test (v0.4 → v0.5)
  - Hybrid retrieval workflow test
  - GPU device selection test

---

## Success Criteria Summary

### Functional Requirements

**ColPali Integration:**
- [ ] ColPali model loads successfully on all devices (CUDA, MPS, CPU)
- [ ] Vision embeddings generated with correct dimensionality (768)
- [ ] Single page, batch, and full PDF embedding functional
- [ ] GPU memory estimation and adaptive batch sizing works
- [ ] CPU fallback triggers on GPU OOM errors

**Dual Storage:**
- [ ] Both text and vision embeddings stored in same collection
- [ ] Embedding types tracked in metadata (`embedding_type` field)
- [ ] Unique ID format enforced (`{doc}_chunk_{n}_text`, `{doc}_page_{n}_vision`)
- [ ] Migration from v0.4 schema successful with no data loss
- [ ] Hybrid queries use RRF with configurable weights

### Performance Targets

- [ ] Vision embedding generation: <5s/page (GPU), <15s/page (CPU)
- [ ] Batch processing speedup: 30%+ vs sequential
- [ ] Storage operations: <100ms per embedding
- [ ] Query latency: <200ms (text), <300ms (vision), <400ms (hybrid)
- [ ] Migration: <1 minute per 1000 embeddings

### Quality Standards

- [ ] Type hints: 100% on all public methods
- [ ] Docstrings: British English, comprehensive examples
- [ ] Test coverage: 100% (ColPaliEmbedder), 90%+ (storage module)
- [ ] Linting: No errors from ruff or mypy
- [ ] All tests pass on both GPU and CPU (GPU tests skip gracefully if unavailable)

---

## Files Created/Modified

### New Files (Estimated ~2,200 lines)

**Source Code:**
- `src/embeddings/colpali_embedder.py` (~350 lines) - Vision embedder class
- `src/storage/schema.py` (~150 lines) - Dual embedding schema
- `src/storage/migration.py` (~200 lines) - v0.4 → v0.5 migration
- `src/storage/dual_store.py` (~500 lines) - Dual embedding storage

**Tests:**
- `tests/embeddings/test_colpali_embedder.py` (~250 lines)
- `tests/integration/test_vision_pipeline.py` (~150 lines)
- `tests/storage/test_dual_store.py` (~200 lines)
- `tests/integration/test_dual_storage_pipeline.py` (~150 lines)

**Documentation:**
- `docs/development/research/colpali-architecture.md` (~100 lines)

### Modified Files

- `pyproject.toml` (+20 lines) - Vision dependencies
- `src/config/settings.py` (+100 lines) - VisionConfig, StorageConfig
- `src/cli/commands/add.py` (+50 lines) - Vision flags
- `src/ingestion/processor.py` (~100 lines modified) - Dual embedding support
- `docs/installation.md` (+30 lines) - GPU setup guide

---

## Dependencies

### Python Packages (Added)

```toml
torch >= 2.0.0              # PyTorch for vision models
transformers >= 4.35.0      # HuggingFace model loading
Pillow >= 10.0.0           # Image processing
pdf2image >= 1.16.3        # PDF to image conversion
```

### System Dependencies

- **poppler-utils** - Required for pdf2image (PDF rendering)
- **CUDA Toolkit 11.8+** - Optional, for NVIDIA GPU acceleration
- **ROCm 5.4+** - Optional, for AMD GPU acceleration

### From Previous Versions

- chromadb >= 0.4.0 (existing)
- numpy >= 1.24.0 (existing)
- All v0.4.0 dependencies

---

## GPU Requirements

**Recommended:**
- CUDA-compatible GPU (NVIDIA) with 8GB+ VRAM
- Apple Silicon (M1/M2/M3) with 16GB+ unified memory
- 16GB+ system RAM for CPU fallback

**Minimum:**
- CPU-only mode supported (slower, 10x+ vs GPU)
- 8GB system RAM

**Batch Size Guidelines:**
- 8GB VRAM: 12 pages per batch
- 4GB VRAM: 4 pages per batch
- CPU: 1-2 pages per batch

---

## Known Limitations

**VISION-001 (ColPali):**
- Model size: ~1.2GB (5-10 minute download on first use)
- GPU highly recommended (CPU is 10x+ slower)
- Vision embeddings 768-dim vs text 384-dim (different spaces, no direct comparison)
- PDF conversion requires poppler system dependency

**VISION-002 (Dual Storage):**
- Storage overhead: Vision embeddings approximately double storage needs
- No cross-type similarity: Cannot directly compare text and vision embeddings
- Hybrid query RRF fusion is heuristic (may not be optimal for all cases)
- Migration requires collection downtime (delete/recreate)

**Shared:**
- Pre-v1.0: Breaking changes possible in schema or API
- No learned fusion weights (fixed text/vision weights in hybrid queries)
- No multi-GPU parallelism yet

---

## Migration Guide (v0.4 → v0.5)

### Before Upgrading

1. **Backup existing data:**
   ```bash
   cp -r ~/.ragged/storage ~/.ragged/storage-backup-v0.4
   ```

2. **Check schema version:**
   ```python
   from ragged.storage.migration import StorageMigration
   migration = StorageMigration(client)
   version = migration.detect_schema_version("documents")
   print(f"Current schema: {version}")  # Should be "v0.4"
   ```

3. **Dry-run migration:**
   ```python
   stats = migration.migrate_collection(
       "documents",
       dry_run=True  # Don't modify, just report
   )
   print(stats)
   ```

### Running Migration

```python
from ragged.storage.migration import StorageMigration
import chromadb

client = chromadb.PersistentClient(path="/path/to/storage")
migration = StorageMigration(client)

# Migrate collection
stats = migration.migrate_collection("documents")

print(f"Migrated {stats['embeddings_migrated']} embeddings")
print(f"Renamed {stats['ids_renamed']} IDs")
print(f"Updated {stats['metadata_updated']} metadata entries")
```

### What Changes

**ID Format:**
- Before: `doc_abc123_chunk_5`
- After: `doc_abc123_chunk_5_text`

**Metadata:**
- Before: `{"chunk_id": "...", "page": 1}`
- After: `{"chunk_id": "...", "page": 1, "embedding_type": "text"}`

**Schema Version:**
- Before: No schema_version metadata
- After: `collection.metadata = {"schema_version": "v0.5"}`

---

## Testing Strategy

### Unit Tests (10-13 hours total)

**ColPali (4-6h):**
- Device detection (CUDA, MPS, CPU, auto)
- Model loading and initialisation
- Single page embedding
- Batch embedding
- PDF document embedding
- VRAM estimation
- Error handling and fallbacks

**Dual Storage (6-7h):**
- Schema validation (IDs, metadata)
- Text embedding storage and retrieval
- Vision embedding storage and retrieval
- Batch operations
- Migration utilities (detection, dry-run, full)
- Query methods (text/vision/hybrid)
- Dimension validation

### Integration Tests (4-6 hours total)

**Vision Pipeline (2-3h):**
- Full PDF → embeddings pipeline
- GPU acceleration validation
- CPU fallback verification
- Large document handling (50+ pages)

**Dual Storage Pipeline (2-3h):**
- End-to-end dual ingestion
- v0.4 → v0.5 migration with real data
- Hybrid retrieval workflow
- Mixed text-only and dual-embedding documents

### Manual Testing

**To be performed in v0.5.6 (Documentation & Tutorials):**
- Visual content quality (diagrams, tables, charts)
- Real-world PDFs (technical papers, reports, presentations)
- GPU memory monitoring on various hardware
- Cross-platform compatibility (Linux, macOS, Windows)

---

## Related Documentation

**Feature Implementation Details:**
- [VISION-001: ColPali Integration](./features/VISION-001-colpali-integration.md) - Complete ColPali implementation (~450 lines with code)
- [VISION-002: Dual Storage](./features/VISION-002-dual-storage.md) - Dual embedding storage architecture (~700 lines with code)

**Context:**
- [v0.5.x Overview](./README.md) - Complete v0.5 series roadmap
- [Testing Specification](./testing.md) - Comprehensive test coverage for v0.5.x
- [v0.4.x Implementation](../v0.4/README.md) - Previous version (knowledge graphs, personal memory)

**Next Steps:**
- [v0.5.1: GPU Management](./v0.5.1.md) - Robust GPU resource handling (builds on v0.5.0)
- [v0.5.2: Vision Retrieval](./v0.5.2.md) - Multi-modal query processing (builds on v0.5.0)

---

**Status:** Planned - Ready for implementation
