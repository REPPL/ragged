# v0.4.5 - Behaviour Learning & Personalisation

**Hours**: 35-40 | **Priority**: P0 - Core Feature | **Status**: Planned

**Dependencies**: v0.4.4 complete (Stable memory system)

---

## Overview

Implement intelligent behaviour learning and personalised ranking based on user interactions and interests.

**Vision**: Ragged learns from user patterns and automatically improves relevance over time.

**Theoretical Foundation**: Applies [Context Engineering 2.0](../../../acknowledgements/context-engineering-2.0.md) **context-aware retrieval** principlesâ€”moving beyond keyword matching to select context based on learned user interests. Personalised ranking reduces uncertainty (entropy reduction) by prioritising information aligned with user focus areas and historical behaviour.

---

## ðŸ” LEANN Decision Point: Storage Evaluation

**Critical**: v0.4.0 includes **LEANN backend decision evaluation** to inform v0.4.0 implementation.

### Purpose

After implementing the complete memory system (v0.4.0-v0.4.0), evaluate actual storage usage to determine if LEANN's 97% storage reduction is needed for v0.4.0.

**Context**: LEANN (graph-based vector storage) offers 97% storage savings over traditional vector stores but adds implementation complexity. The decision to implement LEANN in v0.4.0 is **conditional** based on real-world storage usage.

### Storage Metrics to Collect

**During v0.4.0 development, implement storage monitoring**:

#### Instrumentation (1h)

**Add to v0.4.0 deliverables**:
- Storage monitoring utilities in `ragged/storage/metrics.py` (~100 lines)
- CLI command: `ragged storage stats` to view current usage
- Background tracking of storage growth over time

**Metrics to Track**:
```python
# Storage breakdown
{
    "total_storage_mb": 145.3,
    "breakdown": {
        "vector_db_mb": 120.5,        # ChromaDB vectors
        "memory_db_mb": 18.2,          # SQLite interactions/preferences
        "graph_db_mb": 6.1,            # Kuzu knowledge graph
        "other_mb": 0.5                # Config, logs, etc.
    },
    "document_count": 5000,
    "interaction_count": 1247,
    "storage_per_document_kb": 24.6,   # For 1000 docs = ~24MB
    "projected_10k_docs_mb": 246,      # Linear projection
    "projected_50k_docs_mb": 1230      # ~1.2GB
}
```

#### Collection Period

**Timeline**: Run storage monitoring for 2-4 weeks during/after v0.4.0 development.

**Test Scenarios**:
1. **Small corpus** (100-1000 docs): Typical personal knowledge base
2. **Medium corpus** (5000-10000 docs): Power user
3. **Large corpus** (50000+ docs): Scientific researcher

### LEANN Decision Criteria

**Decision made AFTER v0.4.0 complete, BEFORE v0.4.0 implementation starts.**

#### Proceed with v0.4.0 LEANN Implementation If:

1. **Storage >10GB observed** in realistic use cases
   - Power users consistently hitting >10GB
   - Memory system amplifies storage burden
   - Storage becoming a pain point

2. **Platform requirements acceptable**
   - Target platform is macOS or Linux (not Windows initially)
   - Team comfortable with platform-specific builds
   - C++ build toolchain acceptable

3. **Recall requirements acceptable**
   - Scientific use cases can tolerate <100% recall
   - Graph-based retrieval advantages outweigh recall trade-off
   - 90-95% recall sufficient for most queries

4. **Resource allocation available**
   - Team has bandwidth for v0.4.0 complexity (35-50h)
   - Integration testing resources available
   - Platform-specific testing feasible

#### Defer LEANN to v0.5.x (or later) If:

1. **Storage manageable (<10GB)**
   - Most users staying under 10GB with memory system
   - Storage not a pain point
   - Current architecture scales adequately

2. **Windows users critical**
   - Significant Windows user base
   - Cannot exclude Windows from v0.4.x series
   - Cross-platform parity required

3. **Recall requirements high**
   - Scientific/research use cases need 100% recall
   - Graph approximation accuracy insufficient
   - Traditional vector stores preferred

4. **Resource constraints**
   - Team prefers focus on memory system refinement (v0.4.0-v0.4.0)
   - v0.5.x timeline allows for LEANN later
   - Other priorities higher

### Decision Documentation

**After v0.4.0 complete, document decision**:

**Location**: `docs/development/decisions/adrs/0018-leann-backend-decision.md`

**Required Sections**:
- Storage usage data collected
- Decision criteria evaluation
- Platform and recall trade-offs considered
- Team capacity assessment
- Final decision: Proceed with v0.4.0 or defer to v0.5.x
- Rationale

### Impact on v0.4.9

**If "Proceed"**: Implement v0.4.0 as planned (see [v0.4.0.md](v0.4.0.md))

**If "Defer"**: Skip v0.4.0 LEANN, proceed directly to v0.4.0 (production readiness)

**Timeline**: Decision should be made within 1 week of v0.4.0 completion.

---

## Core Deliverables

### 1. Topic Extraction (4h)

Extract topics from queries for interest profiling.

**Phase 1**: Simple keyword extraction
**Future**: NLP/LLM-based extraction

**Files**:
- `ragged/memory/topics.py` (~200 lines)
- `tests/memory/test_topics.py` (~150 lines)

---

### 2. Behaviour Learner (12h)

Learn from user interaction patterns.

**Features**:
- Track topics queried
- Track documents accessed
- Build interest profiles
- Detect co-occurring topics
- Calculate confidence scores

**Files**:
- `ragged/memory/behaviour.py` (~350 lines)
- `tests/memory/test_behaviour.py` (~200 lines)

---

### 3. Personalised Ranking (10h)

Re-rank results using personal context.

**Algorithm**:
1. Get user interest profile
2. Boost docs related to focus topics
3. Boost previously accessed docs
4. Apply time decay (recent interests weighted more)

**Files**:
- `ragged/memory/personalisation.py` (~200 lines)
- `tests/memory/test_personalization.py` (~150 lines)

---

### 4. RAG Pipeline Integration (8h)

Integrate memory into query flow.

**Enhanced Pipeline**:
```python
query() ->
  switch_persona() ->
  enhance_with_context() ->
  retrieve(k*2) ->
  personalized_rerank(k) ->
  generate() ->
  record_interaction()
```

**Modified**:
- `ragged/core/retrieval.py`
- `ragged/main.py`

---

### 5. Testing & Validation (6-8h)

Validate personalization improvements.

**Tests**:
- Unit tests for each component
- Integration tests for full pipeline
- Manual validation of relevance
- A/B testing infrastructure

---

## Success Criteria

Version 0.4.5 is successful if:

1. âœ… Personalization improves relevance by >15%
2. âœ… Topic extraction 80%+ accuracy
3. âœ… Interest profiles make sense to users
4. âœ… Performance <2s end-to-end
5. âœ… Memory enhancement transparent
6. âœ… Can disable personalization
7. âœ… 85%+ test coverage
8. âœ… Documentation complete

---

## Performance Targets

- Topic extraction: <50ms
- Profile building: <200ms
- Personalized reranking: <100ms
- End-to-end query: <2s

---

## File Summary

**New Files** (~1,850 lines):
- Behaviour learning: ~750 lines
- Storage monitoring: ~100 lines
- Tests: ~500 lines
- Documentation: ~500 lines

---

## Related Documentation

- [v0.4 Overview](README.md) - Release series overview
- [v0.4 Detailed Spec](v0.4-detailed-spec.md) - Part 2: Milestone 2
- [v0.4.4](v0.4.4.md) - Stability (previous)
- [v0.4.6](v0.4.6.md) - Refactoring (next)
- [v0.4.8](v0.4.8.md) - **LEANN backend (conditional)** - Decision made after v0.4.5

---
