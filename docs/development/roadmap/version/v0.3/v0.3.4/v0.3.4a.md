# v0.3.4a - MVP (Docling Core)

**Category:** Modern Document Processing - Phase 1

**Estimated Time:** 25-30 hours

**Status:** Completed

**Completion Date:** 2025-11-19

---

## Overview

Implement the foundational Docling integration for state-of-the-art document processing, delivering 80% of the value with 40% of the total complexity. This MVP phase replaces basic pymupdf text extraction with IBM Research's Docling framework, achieving 30× performance improvement and near-perfect table extraction.

**Current State:** Basic pymupdf text extraction, no OCR, no layout analysis, poor table handling

**Target State:** Production-ready Docling processor with layout analysis, table extraction, and reading order preservation

**Benefits:**
- 30× faster processing than legacy Tesseract approaches
- 97%+ table extraction accuracy (vs <50% with current implementation)
- Proper reading order preservation for multi-column layouts
- Foundation for optional PaddleOCR integration in v0.3.4c
- Structured markdown output ideal for RAG chunking

**Why MVP First:**
- Delivers immediate, substantial value to users
- Validates architectural decisions with real usage
- Reduces risk by isolating Docling integration from PaddleOCR complexity
- Allows user feedback before committing to full implementation
- Simpler installation (no PaddleOCR C++ dependencies)

---

## Prerequisites

**Security & Privacy Foundation (REQUIRED):**

All v0.3.x versions depend on the security and privacy infrastructure established in v0.2.10 and v0.2.11.

- ✅ **v0.2.10 (Security Hardening)** - Pickle vulnerability elimination, session isolation
- ✅ **v0.2.11 (Privacy Infrastructure)** - Encryption at rest, PII detection, GDPR compliance

**Technical Foundation (REQUIRED):**

- ✅ **v0.3.3 (Intelligent Chunking)** - Provides semantic and hierarchical chunking to maximise benefit from improved Docling content extraction

**Why Required:** The improved document structure from Docling will be most effective when paired with intelligent chunking strategies that respect semantic boundaries.

---

## Features

### FEAT-007a: Docling Core Integration (20h)

**Priority:** Critical
**Dependencies:** v0.3.3 (intelligent chunking)

#### Scope

Replace pymupdf-based text extraction with Docling's state-of-the-art document processing pipeline, including layout analysis (DocLayNet), table extraction (TableFormer), and reading order preservation.

**Problem with Current Implementation:**
- No layout analysis (multi-column documents become scrambled)
- No table structure preservation (tables become unstructured text)
- No OCR capability (scanned documents fail completely)
- No reading order detection (text extracted in wrong sequence)

**Docling Solution:**
- DocLayNet model for precise layout analysis
- TableFormer for accurate table structure extraction
- Built-in reading order detection
- Foundation for future OCR integration
- Structured markdown output with preserved semantics

#### Implementation Overview

- **Module:** `src/processing/docling_processor.py`
- **Approach:** Plugin architecture with processor interface
- **Libraries:** docling, docling-core, docling-parse (all MIT licence)
- **Strategy:** Direct Docling pipeline integration with configuration framework

#### Key Components

- `BaseProcessor` interface (defines processor contract)
- `DoclingProcessor` implementation
- `ProcessorConfig` dataclass for configuration
- `ProcessedDocument` output format
- Integration with existing ingestion pipeline
- Model management (lazy loading, caching)

#### Algorithm

```
PDF Document
    ↓
Load with Docling Document API
    ↓
Apply DocLayNet (layout analysis)
    ↓
Apply TableFormer (table extraction)
    ↓
Detect reading order
    ↓
Extract structured content:
    - Text blocks with layout metadata
    - Tables with structure preserved
    - Images with captions
    ↓
Convert to markdown format
    ↓
Pass to intelligent chunking (v0.3.3)
    ↓
Store in vector database
```

---

### FEAT-008a: Processor Architecture (8h)

**Priority:** Critical
**Dependencies:** None

#### Scope

Design and implement a plugin-based processor architecture that allows multiple document processors (current: pymupdf, new: Docling, future: PaddleOCR) to coexist with a unified interface.

**Architectural Goals:**
- Clean separation between processor implementations
- Easy addition of new processors (v0.3.4c will add PaddleOCR)
- Configuration-driven processor selection
- Backwards compatibility with existing pymupdf processor
- Support for processor-specific options

#### Implementation Overview

- **Module:** `src/processing/base.py`
- **Approach:** Abstract base class with concrete implementations
- **Pattern:** Strategy pattern for processor selection
- **Factory:** `ProcessorFactory` for instantiation

#### Key Components

```python
# Base interface
class BaseProcessor(ABC):
    @abstractmethod
    def process(self, file_path: Path) -> ProcessedDocument:
        """Process document and return structured content"""
        pass

    @abstractmethod
    def supports_file_type(self, file_path: Path) -> bool:
        """Check if processor can handle this file type"""
        pass

# Concrete implementations
class LegacyPyMuPDFProcessor(BaseProcessor):
    """Existing pymupdf processor for backwards compatibility"""
    pass

class DoclingProcessor(BaseProcessor):
    """New Docling-based processor (v0.3.4a)"""
    pass

# Factory for selection
class ProcessorFactory:
    @staticmethod
    def create(processor_type: str, config: ProcessorConfig) -> BaseProcessor:
        """Create processor instance based on configuration"""
        pass
```

---

## Implementation Phases

### Phase 1: Architecture Setup (8h)

**Sessions 1-2:**

#### Session 1: Foundation (4h)
- Create `src/processing/` directory structure
- Design `BaseProcessor` abstract interface
- Design `ProcessedDocument` output format
- Create `ProcessorConfig` dataclass
- Implement `ProcessorFactory` with plugin registration
- Document architecture decisions (ADR)

**Deliverables:**
- Complete processor interface
- Factory pattern implementation
- Configuration framework
- Architecture decision record

#### Session 2: Legacy Migration (4h)
- Refactor existing pymupdf code into `LegacyPyMuPDFProcessor`
- Ensure backwards compatibility
- Add processor selection logic to ingestion pipeline
- Unit tests for factory and legacy processor
- Validate existing functionality preserved

**Deliverables:**
- Working legacy processor
- Processor selection working
- No regression in existing functionality
- Test coverage for legacy path

---

### Phase 2: Docling Integration (12h)

**Sessions 3-5:**

#### Session 3: Basic Docling Integration (4h)
- Add docling dependencies to pyproject.toml
- Implement `DoclingProcessor` class skeleton
- Basic PDF loading with Docling API
- Simple text extraction (no models yet)
- Configuration for Docling options
- Unit tests for basic functionality

**Deliverables:**
- Docling dependencies installed
- Basic processor implementation
- Simple text extraction working

#### Session 4: Model Integration (4h)
- Integrate DocLayNet model (layout analysis)
- Integrate TableFormer model (table extraction)
- Implement model lazy loading (download on first use)
- Model caching to avoid re-downloads
- Handle model download failures gracefully
- Progress indicators for model downloads

**Deliverables:**
- DocLayNet layout analysis functional
- TableFormer table extraction working
- Model management robust
- User-friendly download experience

#### Session 5: Output Processing (4h)
- Implement markdown conversion from Docling output
- Preserve table structure in markdown format
- Reading order preservation
- Metadata extraction (page numbers, confidence scores)
- Integration with `ProcessedDocument` format
- Handle edge cases (empty pages, images only, etc.)

**Deliverables:**
- High-quality markdown output
- Preserved document structure
- Comprehensive metadata
- Edge cases handled

---

### Phase 3: Pipeline Integration (5h)

**Sessions 6-7:**

#### Session 6: Ingestion Integration (3h)
- Connect Docling processor to ingestion pipeline
- Configuration for processor selection (legacy vs Docling)
- CLI option: `--processor docling` or `--processor legacy`
- Default to Docling for new installations
- Update configuration schema
- Integration tests for full pipeline

**Deliverables:**
- Docling integrated into main pipeline
- Processor selection configurable
- CLI options working
- Integration tests passing

#### Session 7: Chunking Integration (2h)
- Ensure Docling output compatible with semantic chunking
- Test with hierarchical chunking
- Validate markdown format for chunker input
- Performance testing with intelligent chunking
- End-to-end tests (PDF → Docling → Chunking → Vector DB)

**Deliverables:**
- Seamless integration with v0.3.3 chunking
- End-to-end pipeline working
- Performance benchmarks recorded

---

### Phase 4: Testing & Validation (3-4h)

**Session 8:**

#### Comprehensive Testing (3-4h)
- Create test document corpus:
  - Born-digital PDFs (simple text)
  - Multi-column layouts
  - Complex tables
  - Mixed content (text + images)
- Compare Docling vs legacy pymupdf quality
- Table extraction accuracy validation (manual review)
- Performance benchmarking (processing speed)
- Memory usage profiling
- Edge case testing (corrupted PDFs, password-protected, etc.)

**Deliverables:**
- Complete test corpus
- Quality comparison report
- Performance benchmarks
- Memory usage analysis
- Edge case handling validated

---

### Phase 5: Documentation & Release (2-4h)

**Session 9:**

#### Documentation (2h)
- User guide: "Upgrading to Docling Processor"
- Migration guide: Legacy → Docling
- Configuration reference
- Performance comparison documentation
- Troubleshooting guide (model downloads, etc.)
- Update README with new capabilities

**Deliverables:**
- Complete user documentation
- Migration guide
- Configuration reference

#### Release Preparation (2h)
- Final testing pass
- Create release notes for v0.3.4a
- Update CHANGELOG.md
- Tag v0.3.4a release
- Prepare announcement (what's new, benefits, migration path)

**Deliverables:**
- Release notes
- Tagged release
- Announcement ready

---

## Technical Architecture

### Directory Structure

```
src/processing/
├── __init__.py                 # Package initialisation
├── base.py                     # BaseProcessor interface (150 lines)
│   ├── class BaseProcessor (ABC)
│   ├── class ProcessedDocument (dataclass)
│   └── class ProcessorConfig (dataclass)
├── factory.py                  # ProcessorFactory (100 lines)
│   └── class ProcessorFactory
├── legacy_processor.py         # LegacyPyMuPDFProcessor (200 lines)
│   └── class LegacyPyMuPDFProcessor(BaseProcessor)
├── docling_processor.py        # DoclingProcessor (300 lines)
│   └── class DoclingProcessor(BaseProcessor)
└── model_manager.py            # Model lazy loading (150 lines)
    └── class ModelManager

tests/processing/
├── test_base.py                # Interface tests
├── test_factory.py             # Factory tests
├── test_legacy_processor.py    # Legacy processor tests
├── test_docling_processor.py   # Docling processor tests
├── test_integration.py         # End-to-end tests
└── fixtures/
    └── test_documents/         # Test PDFs
```

### Processor Interface

```python
from abc import ABC, abstractmethod
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional


@dataclass
class ProcessedDocument:
    """Standardised output format from all processors"""
    content: str                    # Markdown-formatted text
    tables: List[Dict]              # Extracted tables with structure
    images: List[Dict]              # Images with metadata
    metadata: Dict                  # Processing metadata
    confidence: float               # Overall confidence score
    processor_type: str             # Which processor was used


@dataclass
class ProcessorConfig:
    """Configuration for document processors"""
    processor_type: str = "docling"     # "docling" or "legacy"
    enable_table_extraction: bool = True
    enable_layout_analysis: bool = True
    model_cache_dir: Optional[Path] = None
    batch_size: int = 1
    # Processor-specific options
    options: Dict = None


class BaseProcessor(ABC):
    """Abstract base class for document processors"""

    def __init__(self, config: ProcessorConfig):
        self.config = config

    @abstractmethod
    def process(self, file_path: Path) -> ProcessedDocument:
        """
        Process document and return structured content.

        Args:
            file_path: Path to document file

        Returns:
            ProcessedDocument with extracted content

        Raises:
            ProcessingError: If document cannot be processed
        """
        pass

    @abstractmethod
    def supports_file_type(self, file_path: Path) -> bool:
        """Check if processor can handle this file type"""
        pass

    @abstractmethod
    def get_capabilities(self) -> Dict[str, bool]:
        """Return processor capabilities (OCR, tables, layout, etc.)"""
        pass
```

### Factory Implementation

```python
class ProcessorFactory:
    """Factory for creating document processors"""

    _processors = {
        "legacy": LegacyPyMuPDFProcessor,
        "docling": DoclingProcessor,
    }

    @classmethod
    def create(cls, config: ProcessorConfig) -> BaseProcessor:
        """Create processor based on configuration"""
        processor_class = cls._processors.get(config.processor_type)

        if processor_class is None:
            raise ValueError(f"Unknown processor: {config.processor_type}")

        return processor_class(config)

    @classmethod
    def register_processor(cls, name: str, processor_class: type):
        """Register new processor (for v0.3.4c PaddleOCR)"""
        cls._processors[name] = processor_class
```

### Docling Processor Implementation

```python
from docling.document import Document
from docling.pipeline import Pipeline
from docling.models import DocLayNet, TableFormer


class DoclingProcessor(BaseProcessor):
    """Docling-based document processor"""

    def __init__(self, config: ProcessorConfig):
        super().__init__(config)
        self.model_manager = ModelManager(config.model_cache_dir)
        self._pipeline = None  # Lazy initialisation

    @property
    def pipeline(self) -> Pipeline:
        """Lazy-load Docling pipeline"""
        if self._pipeline is None:
            models = []

            if self.config.enable_layout_analysis:
                models.append(self.model_manager.get_model("DocLayNet"))

            if self.config.enable_table_extraction:
                models.append(self.model_manager.get_model("TableFormer"))

            self._pipeline = Pipeline(models)

        return self._pipeline

    def process(self, file_path: Path) -> ProcessedDocument:
        """Process PDF with Docling"""
        # Load document
        doc = Document.from_pdf(file_path)

        # Apply ML pipeline
        doc = self.pipeline(doc)

        # Extract structured content
        return ProcessedDocument(
            content=doc.to_markdown(),
            tables=self._extract_tables(doc),
            images=self._extract_images(doc),
            metadata=self._extract_metadata(doc),
            confidence=self._calculate_confidence(doc),
            processor_type="docling"
        )

    def supports_file_type(self, file_path: Path) -> bool:
        """Docling supports PDF files"""
        return file_path.suffix.lower() == ".pdf"

    def get_capabilities(self) -> Dict[str, bool]:
        """Docling capabilities"""
        return {
            "ocr": False,  # Not in v0.3.4a (requires v0.3.4c)
            "tables": True,
            "layout_analysis": True,
            "reading_order": True,
            "images": True,
        }
```

---

## Risk Analysis & Mitigation

### Technical Risks

| Risk | Impact | Probability | Mitigation | Detection |
|------|--------|------------|------------|-----------|
| Model download failures | High | Low | Retry logic, manual download instructions, clear error messages | Model manager tests, integration tests |
| Memory consumption (large PDFs) | High | Medium | Process page-by-page, streaming where possible, memory profiling | Performance tests with large documents |
| Docling API changes | Medium | Low | Pin specific version (^2.5.0), monitor releases, test before upgrades | CI tests, version compatibility checks |
| Performance regression (some cases) | Low | Low | Benchmarking, allow processor selection, maintain legacy option | Performance test suite |
| Backwards compatibility breaks | Medium | Medium | Maintain legacy processor, migration guide, gradual rollout | Integration tests, user testing |

### Mitigation Strategies

**Model Download Reliability:**
```python
class ModelManager:
    def get_model(self, model_name: str, max_retries: int = 3):
        """Download model with retry logic"""
        for attempt in range(max_retries):
            try:
                return self._download_and_cache(model_name)
            except NetworkError as e:
                if attempt == max_retries - 1:
                    logger.error(
                        f"Failed to download {model_name}. "
                        "Please download manually from: {url}"
                    )
                    raise
                logger.warning(f"Retry {attempt + 1}/{max_retries}")
                time.sleep(2 ** attempt)  # Exponential backoff
```

**Memory Management:**
```python
def process_large_document(self, file_path: Path) -> ProcessedDocument:
    """Process large documents page-by-page"""
    doc = fitz.open(file_path)

    # Estimate memory requirements
    page_count = len(doc)
    if page_count > 100:  # Large document
        return self._process_streaming(doc)
    else:
        return self._process_standard(doc)
```

---

## Quality Gates

### Functional Requirements

- [ ] BaseProcessor interface fully defined and documented
- [ ] ProcessorFactory creates correct processor instances
- [ ] Legacy processor maintains existing functionality (no regressions)
- [ ] Docling processor extracts text accurately
- [ ] DocLayNet layout analysis preserves reading order
- [ ] TableFormer extracts tables with structure preserved
- [ ] Markdown output format valid and well-structured
- [ ] Processor selection configurable via CLI and config file
- [ ] Model lazy loading works (download only when needed)
- [ ] Model caching prevents redundant downloads

### Performance Requirements

- [ ] Born-digital PDFs process in <2s per 100 pages (vs 5s current)
- [ ] Table extraction 10× faster than current implementation
- [ ] Memory usage <2GB for 1000-page documents
- [ ] Model downloads show progress indicators
- [ ] No memory leaks during large batch processing

### Quality Requirements

- [ ] Table structure extraction accuracy >97% (manual validation on test corpus)
- [ ] Reading order preserved correctly (multi-column layouts)
- [ ] Text extraction accuracy >99% for born-digital PDFs
- [ ] Markdown output compatible with semantic chunking
- [ ] Edge cases handled gracefully (empty pages, corrupted PDFs)

### Code Quality Requirements

- [ ] 95%+ test coverage for new code
- [ ] All unit tests passing
- [ ] Integration tests for full pipeline passing
- [ ] Type hints complete (mypy strict mode)
- [ ] Docstrings complete (British English, Google style)
- [ ] No pylint warnings (score >9.5)
- [ ] Architecture decision record created

---

## Execution Checklist

### Pre-Implementation

- [ ] Create feature branch: `git checkout -b feature/v0.3.4a-docling-core`
- [ ] Review Docling documentation thoroughly
- [ ] Design processor interface (use architecture-advisor agent)
- [ ] Add dependencies to pyproject.toml:
  ```toml
  docling = "^2.5.0"
  docling-core = "^2.0.0"
  docling-parse = "^2.0.0"
  ```
- [ ] Create ADR for processor architecture

### Architecture Setup

- [ ] Create `src/processing/` directory
- [ ] Implement `BaseProcessor` interface in `base.py`
- [ ] Implement `ProcessedDocument` dataclass
- [ ] Implement `ProcessorConfig` dataclass
- [ ] Implement `ProcessorFactory` in `factory.py`
- [ ] Unit tests for factory and interfaces
- [ ] Architecture review (architecture-advisor agent)

### Legacy Processor Migration

- [ ] Create `legacy_processor.py`
- [ ] Refactor existing pymupdf code into `LegacyPyMuPDFProcessor`
- [ ] Implement `BaseProcessor` interface
- [ ] Add processor selection to ingestion pipeline
- [ ] Unit tests for legacy processor
- [ ] Integration tests (verify no regression)

### Docling Integration

- [ ] Install Docling dependencies
- [ ] Create `docling_processor.py`
- [ ] Implement `DoclingProcessor` class skeleton
- [ ] Basic PDF loading with Docling API
- [ ] Unit tests for basic functionality
- [ ] Integrate DocLayNet model (layout analysis)
- [ ] Integrate TableFormer model (table extraction)
- [ ] Implement `ModelManager` for lazy loading
- [ ] Add model download progress indicators
- [ ] Implement markdown conversion
- [ ] Extract tables with structure preservation
- [ ] Extract metadata and confidence scores
- [ ] Unit tests for all Docling functionality

### Pipeline Integration

- [ ] Connect Docling processor to ingestion pipeline
- [ ] Add configuration options (processor selection)
- [ ] Add CLI option: `--processor docling|legacy`
- [ ] Default to Docling for new installations
- [ ] Test with semantic chunking (v0.3.3)
- [ ] Test with hierarchical chunking (v0.3.3)
- [ ] Integration tests for full pipeline
- [ ] End-to-end tests (PDF → Docling → Chunking → Vector DB)

### Testing & Validation

- [ ] Create test document corpus (born-digital, tables, multi-column)
- [ ] Compare Docling vs legacy quality (manual review)
- [ ] Table extraction accuracy validation (>97% target)
- [ ] Performance benchmarking (30× target vs Tesseract baseline)
- [ ] Memory usage profiling
- [ ] Edge case testing (empty pages, corrupted PDFs, password-protected)
- [ ] Large document testing (1000+ pages)

### Documentation

- [ ] User guide: "Upgrading to Docling Processor"
- [ ] Migration guide (legacy → Docling)
- [ ] Configuration reference
- [ ] Performance comparison documentation
- [ ] Troubleshooting guide (model downloads, etc.)
- [ ] Update README.md with Docling capabilities
- [ ] API documentation (processor interface)
- [ ] Run documentation-auditor agent

### Release

- [ ] Final testing pass (all tests passing)
- [ ] Create release notes for v0.3.4a
- [ ] Update CHANGELOG.md
- [ ] Use git-documentation-committer agent
- [ ] Tag v0.3.4a release
- [ ] Prepare announcement

### Post-Implementation

- [ ] Update implementation record in `docs/development/implementation/`
- [ ] Record actual hours vs estimate (time-log)
- [ ] Document quality improvements (benchmarks, metrics)
- [ ] Document lessons learned (devlog)
- [ ] Update v0.3.4/README.md progress
- [ ] User feedback collection plan

---

## Agent Workflow (6-8h)

1. **architecture-advisor (2-3h):** Processor architecture design, interface validation, risk assessment
2. **documentation-architect (2h):** User guide structure, migration guide planning
3. **documentation-auditor (1-2h):** Comprehensive documentation review
4. **git-documentation-committer (1h):** Final commit with quality checks

---

## Deliverables

1. **Processor Architecture** - Clean, extensible plugin system for multiple processors
2. **Docling Integration** - Production-ready DocLayNet + TableFormer processing
3. **Legacy Compatibility** - Existing pymupdf processor maintained for backwards compatibility
4. **Performance Improvement** - 30× faster processing for born-digital documents
5. **Table Extraction** - 97%+ accuracy with structure preservation
6. **Documentation** - Complete user guides, migration path, configuration reference
7. **Foundation for v0.3.4c** - Architecture ready for optional PaddleOCR integration

---

## Success Criteria

- ✅ Docling processor processes born-digital PDFs with >99% text extraction accuracy
- ✅ Table extraction achieves >97% structure preservation (manual validation)
- ✅ Processing speed 30× faster than legacy Tesseract baseline
- ✅ Multi-column layouts preserve correct reading order
- ✅ Memory usage <2GB for 1000-page documents
- ✅ Model downloads reliable with clear progress indicators
- ✅ All tests passing (95%+ coverage)
- ✅ Documentation complete and approved by auditor
- ✅ No regressions in existing functionality
- ✅ Architecture ready for v0.3.4b (quality assessment) and v0.3.4c (PaddleOCR)

---

## Related Documentation

- [v0.3.4 Implementation Plan](../../../planning/version/v0.3.4-implementation-plan.md) - Overall strategy and analysis
- [v0.3.4b Roadmap](./v0.3.4b.md) - Next phase: Intelligent routing
- [v0.3.4c Roadmap](./v0.3.4c.md) - Optional phase: PaddleOCR integration
- [v0.3.4 Overview](../v0.3.4.md) - Combined version roadmap
- [v0.3.3 Roadmap](../v0.3.3.md) - Prerequisite: Intelligent chunking

---

**Status:** Planned
