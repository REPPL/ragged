# v0.3.10 - Performance & Quality Tools

**Category:** CLI - Measurement & Optimisation

**Estimated Time:** 19-24 hours

**Status:** Planned

---

## Overview

Bottleneck identification and quality dashboards for production optimisation.

**Target Users:** DevOps, performance engineers, researchers, power users

**Key Innovation:** Real-time performance profiling and quality metrics enable data-driven optimisation without guesswork.

---

## Prerequisites

**Security & Privacy Foundation (REQUIRED):**

All v0.3.x versions depend on the security and privacy infrastructure established in v0.2.10 and v0.2.11. These versions MUST be completed before implementing any v0.3.x features.

- âœ… **v0.2.10 (Security Hardening)** - Eliminates Pickle vulnerabilities, implements session isolation, establishes security testing framework
- âœ… **v0.2.11 (Privacy Infrastructure)** - Provides encryption at rest, PII detection/redaction, data lifecycle management, GDPR compliance

**Why Required:** v0.3.10 stores query metrics in SQLite database. v0.2.11 provides query hashing, encryption, and TTL policies to protect user privacy.

---

## Features

### CLI-014: Performance Profiling (5-6h)

**Priority:** High
**Dependencies:** v0.3.9 (debug mode for integration)

#### Scope

Comprehensive performance profiling for identifying bottlenecks in RAG pipeline.

**Use Cases:**
- Identify slow operations
- Optimise query latency
- Reduce memory usage
- Benchmark configuration changes
- Production performance monitoring

**User Experience:**
```bash
$ ragged profile query "what are the main findings?"

â±ï¸ Performance Profile: Query Pipeline

Pipeline Breakdown:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage                â”‚ Duration â”‚ %Total  â”‚ Memory  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Query Preprocessing  â”‚ 2ms      â”‚ 0.1%    â”‚ 0.5MB   â”‚
â”‚ Query Embedding      â”‚ 45ms     â”‚ 3.3%    â”‚ 12MB    â”‚
â”‚ Vector Retrieval     â”‚ 23ms     â”‚ 1.7%    â”‚ 8MB     â”‚
â”‚ Reranking            â”‚ 67ms     â”‚ 4.9%    â”‚ 24MB    â”‚
â”‚ Context Building     â”‚ 3ms      â”‚ 0.2%    â”‚ 2MB     â”‚
â”‚ Generation (LLM)     â”‚ 1,234ms  â”‚ 89.8%   â”‚ 156MB   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total: 1,374ms (Memory peak: 202MB)

ğŸ” Bottleneck Analysis:
  âš ï¸  Generation (LLM) taking 89.8% of total time
      â†’ Consider using faster model or caching
  âœ“   Vector retrieval optimal (23ms for 5 chunks)
  âœ“   Reranking acceptable (67ms)

Recommendations:
  1. Enable response caching for repeated queries
  2. Consider streaming generation for better UX
  3. Current performance: Good (< 2s target)

$ ragged profile add documents/large_book.pdf

â±ï¸ Performance Profile: Document Ingestion

Ingestion Breakdown:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage                â”‚ Duration â”‚ %Total  â”‚ Memory  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PDF Loading          â”‚ 234ms    â”‚ 2.1%    â”‚ 45MB    â”‚
â”‚ OCR Processing       â”‚ 8,456ms  â”‚ 75.2%   â”‚ 512MB   â”‚
â”‚ Markdown Conversion  â”‚ 123ms    â”‚ 1.1%    â”‚ 28MB    â”‚
â”‚ Chunking             â”‚ 456ms    â”‚ 4.1%    â”‚ 67MB    â”‚
â”‚ Embedding Generation â”‚ 1,876ms  â”‚ 16.7%   â”‚ 234MB   â”‚
â”‚ Vector Storage       â”‚ 89ms     â”‚ 0.8%    â”‚ 12MB    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total: 11,234ms (Memory peak: 898MB)

ğŸ” Bottleneck Analysis:
  âš ï¸  OCR Processing taking 75.2% of total time
      â†’ Document quality: Good (using Docling)
      â†’ Consider GPU acceleration for batch processing
  âš ï¸  Embedding generation taking 16.7%
      â†’ Batch size: 32 (optimal)
  âœ“   Vector storage optimal (89ms)
```

#### Implementation Overview

- **Module:** `src/cli/commands/profile.py`
- **Approach:** Python's `cProfile` + custom timing decorators
- **Libraries:** cProfile (stdlib), memory_profiler, rich (tables)
- **Integration:** Wraps all major operations

#### Key Components

- `Profiler` class with context managers
- Stage-level timing decorators
- Memory tracking
- Bottleneck detection heuristics
- Formatted output with tables
- Profiling report export (JSON, CSV)

---

### CLI-015: Quality Metrics Dashboard (6-8h)

**Priority:** High
**Dependencies:** v0.3.1 (RAGAS metrics)

#### Scope

Real-time quality metrics dashboard for monitoring RAG performance.

**Use Cases:**
- Monitor RAGAS scores over time
- Detect quality regressions
- Validate configuration changes
- Compare retrieval strategies
- Track system health

**User Experience:**
```bash
$ ragged metrics

ğŸ“Š ragged Quality Metrics Dashboard

System Overview:
  Documents: 127
  Total Chunks: 12,847
  Vector Database: ChromaDB (342MB)
  Last Update: 2 hours ago

RAGAS Scores (last 100 queries):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric                  â”‚ Mean   â”‚ Median â”‚ P95    â”‚ P99    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Context Precision       â”‚ 0.87   â”‚ 0.89   â”‚ 0.95   â”‚ 0.98   â”‚
â”‚ Context Recall          â”‚ 0.82   â”‚ 0.84   â”‚ 0.91   â”‚ 0.94   â”‚
â”‚ Faithfulness            â”‚ 0.91   â”‚ 0.93   â”‚ 0.97   â”‚ 0.99   â”‚
â”‚ Answer Relevancy        â”‚ 0.85   â”‚ 0.87   â”‚ 0.93   â”‚ 0.96   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Overall RAGAS: 0.86 (Target: > 0.80) âœ…

Retrieval Performance (last 100 queries):
  Average Chunks Retrieved: 5.2
  Average Retrieval Time: 24ms
  Average Confidence: 0.89
  Failed Retrievals: 0 (0.0%)

Generation Performance:
  Average Generation Time: 1,234ms
  Average Tokens: input=1,247, output=156
  Failed Generations: 2 (2.0%)

Quality Trends (last 7 days):
  ğŸ“ˆ Context Precision: +0.03 (0.84 â†’ 0.87)
  ğŸ“ˆ Faithfulness: +0.02 (0.89 â†’ 0.91)
  ğŸ“‰ Answer Relevancy: -0.01 (0.86 â†’ 0.85)

$ ragged metrics --export metrics_report.json
âœ“ Metrics exported to metrics_report.json

$ ragged metrics --compare config1.yaml config2.yaml

ğŸ“Š Configuration Comparison

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric                  â”‚ Config 1 â”‚ Config 2 â”‚ Î”      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Context Precision       â”‚ 0.87     â”‚ 0.89     â”‚ +0.02  â”‚
â”‚ Context Recall          â”‚ 0.82     â”‚ 0.85     â”‚ +0.03  â”‚
â”‚ Faithfulness            â”‚ 0.91     â”‚ 0.90     â”‚ -0.01  â”‚
â”‚ Answer Relevancy        â”‚ 0.85     â”‚ 0.88     â”‚ +0.03  â”‚
â”‚ Overall RAGAS           â”‚ 0.86     â”‚ 0.88     â”‚ +0.02  â”‚
â”‚ Avg Query Time          â”‚ 1,374ms  â”‚ 1,567ms  â”‚ +193ms â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Recommendation: Config 2 has better quality (+0.02 RAGAS) but slower (193ms)
                Trade-off: Quality vs Speed
```

#### Implementation Overview

- **Module:** `src/cli/commands/metrics.py`
- **Approach:** Persistent metrics storage + real-time aggregation
- **Storage:** SQLite for metrics history
- **Integration:** Hooks into query and ingestion pipelines

#### Key Components

- `MetricsCollector` class
- SQLite metrics database
- RAGAS score aggregation
- Performance statistics
- Trend analysis (time-series)
- Dashboard rendering (rich tables)
- Export functionality (JSON, CSV)
- Configuration comparison

---

## Privacy & Security Implementation

**Critical Privacy Requirements:** Metrics database stores query text, performance data, and quality scores which may reveal sensitive user information. ALL query data MUST be anonymized and protected using v0.2.11 privacy infrastructure.

### Query Anonymization (v0.2.11 Integration)

**1. Query Hashing (NOT Plaintext Storage)**

The metrics database NEVER stores plaintext queries. All queries are hashed using v0.2.11's PII detection:

```python
# src/cli/commands/metrics.py - Database storage
from src.security.pii import hash_query
import sqlite3

class MetricsDatabase:
    def record_query(
        self,
        question: str,  # Original query
        answer: str,
        metrics: Dict[str, float],
        session_id: str
    ) -> None:
        """Record query metrics with privacy protection (v0.2.11)."""
        # Hash query (one-way, cannot reverse)
        query_hash = hash_query(question)  # v0.2.11

        # Store only hash, NOT plaintext
        self.conn.execute("""
            INSERT INTO queries (
                session_id,
                query_hash,        -- âœ… HASHED (v0.2.11)
                -- NOT: query_text  âŒ Would be PII violation
                duration_ms,
                chunks_retrieved,
                avg_confidence,
                context_precision,
                context_recall,
                faithfulness,
                answer_relevancy,
                ragas_score,
                timestamp,
                expires_at         -- âœ… TTL (v0.2.11)
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            session_id,
            query_hash,  # Hashed, not plaintext
            metrics['duration_ms'],
            metrics['chunks_retrieved'],
            metrics['avg_confidence'],
            metrics.get('context_precision'),
            metrics.get('context_recall'),
            metrics.get('faithfulness'),
            metrics.get('answer_relevancy'),
            metrics.get('ragas_score'),
            datetime.now(),
            datetime.now() + timedelta(days=90)  # TTL from v0.2.11
        ))

        logger.info(f"Recorded metrics for query hash: {query_hash[:16]}")
```

**Stored:** Query hash (SHA-256, 16 chars)
**NOT Stored:** Original query text
**Benefit:** Even with database access, cannot recover original queries

**2. Database Schema (Privacy-First)**

```sql
-- SQLite schema with privacy protection
CREATE TABLE queries (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id TEXT NOT NULL,           -- Session isolation (v0.2.10)
    query_hash TEXT NOT NULL,           -- âœ… HASHED query (v0.2.11)
    duration_ms REAL,
    chunks_retrieved INTEGER,
    avg_confidence REAL,
    context_precision REAL,
    context_recall REAL,
    faithfulness REAL,
    answer_relevancy REAL,
    ragas_score REAL,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    expires_at DATETIME NOT NULL,       -- âœ… TTL expiration (v0.2.11)

    -- Indexes for performance
    INDEX idx_session (session_id),
    INDEX idx_hash (query_hash),
    INDEX idx_expires (expires_at)
);

-- NO query_text column (would violate privacy)
-- NO answer_text column (would violate privacy)
-- NO document_content column (would violate privacy)
```

**Privacy Features:**
- `query_hash`: One-way hash, cannot reverse
- `session_id`: Session isolation (v0.2.10)
- `expires_at`: Automatic TTL-based deletion (v0.2.11)

**3. Database Encryption at Rest**

SQLite database file encrypted using v0.2.11:

```python
# Database file encryption
from src.security.encryption import get_encryption_manager
import sqlite3

class MetricsDatabase:
    def __init__(self, db_path: Path = None):
        if db_path is None:
            db_path = Path.home() / ".ragged" / "metrics" / "metrics.db"

        self.db_path = db_path
        self.db_path.parent.mkdir(parents=True, exist_ok=True, mode=0o700)

        # Connect to database
        self.conn = sqlite3.connect(str(db_path))

        # Set restrictive permissions
        import os
        os.chmod(db_path, 0o600)  # User read/write only

        self._init_schema()

        logger.info(f"Metrics database initialized: {db_path} (permissions: 0o600)")
```

**File Location:** `~/.ragged/metrics/metrics.db`
**Permissions:** 0o600 (user read/write only)
**Encryption:** File-level encryption possible via OS (FileVault, LUKS, BitLocker)

**Note:** SQLite doesn't support native encryption. For additional security, recommend:
- Encrypted filesystem (user should enable FileVault/LUKS/BitLocker)
- Or use SQLCipher (encrypted SQLite) in future version

### Data Lifecycle Management (v0.2.11 Integration)

**1. Automatic TTL-Based Cleanup**

Metrics expire automatically using v0.2.11 lifecycle management:

```python
# TTL cleanup integration
from src.core.cleanup import get_cleanup_scheduler

def cleanup_expired_metrics() -> int:
    """Clean up expired metrics (v0.2.11 TTL)."""
    db = MetricsDatabase()

    # Delete rows where expires_at < now
    cursor = db.conn.execute("""
        DELETE FROM queries
        WHERE expires_at < ?
    """, (datetime.now(),))

    removed = cursor.rowcount
    db.conn.commit()

    if removed > 0:
        logger.info(f"Cleaned up {removed} expired metrics")

    # Also vacuum database to reclaim space
    db.conn.execute("VACUUM")

    return removed

# Register with v0.2.11 cleanup scheduler
cleanup_scheduler = get_cleanup_scheduler()
cleanup_scheduler.register_cleanup_task(cleanup_expired_metrics)
```

**Default TTL:** 90 days
**User Control:** Configurable via `metrics_ttl_days`
**Manual Cleanup:** `ragged cleanup metrics`

**2. User-Controlled Retention**

Users can customize metrics retention:

```python
# Configuration for metrics retention
class Settings(BaseSettings):
    # Metrics privacy
    metrics_ttl_days: int = 90          # Default: 3 months
    metrics_enable: bool = True         # Can disable entirely
    metrics_session_isolation: bool = True  # Per-session metrics
```

**Privacy Commands:**

```bash
# Show metrics retention policy
$ ragged config metrics show-policy
Metrics Retention Policy:
  Collection: Enabled
  TTL: 90 days
  Session Isolation: Enabled
  Total Records: 1,247
  Oldest Record: 2024-08-19 (62 days ago)
  Disk Usage: 2.3 MB

# Adjust TTL
$ ragged config set metrics_ttl_days 30
âœ“ Metrics TTL set to 30 days

# Clear all metrics
$ ragged cleanup metrics --all
âš ï¸  Delete all 1,247 metrics records? (y/n): y
âœ“ Deleted 1,247 records
âœ“ Database vacuumed (reclaimed 2.3 MB)
```

### GDPR Compliance

**Right to Deletion (Article 17):**

```python
# GDPR deletion for metrics
def delete_metrics_data(session_id: Optional[str] = None) -> int:
    """Delete metrics data (GDPR Article 17)."""
    db = MetricsDatabase()

    if session_id:
        # Delete specific session's metrics
        cursor = db.conn.execute("""
            DELETE FROM queries WHERE session_id = ?
        """, (session_id,))
    else:
        # Delete ALL metrics
        cursor = db.conn.execute("DELETE FROM queries")

    removed = cursor.rowcount
    db.conn.commit()
    db.conn.execute("VACUUM")  # Reclaim space

    logger.info(f"GDPR deletion: removed {removed} metrics records")
    return removed
```

**Right to Export (Article 20):**

```python
# Export metrics data
def export_metrics_data(output_path: Path, session_id: Optional[str] = None) -> None:
    """Export metrics (GDPR Article 20)."""
    import json

    db = MetricsDatabase()

    if session_id:
        cursor = db.conn.execute("""
            SELECT * FROM queries WHERE session_id = ?
        """, (session_id,))
    else:
        cursor = db.conn.execute("SELECT * FROM queries")

    # Convert to JSON
    columns = [desc[0] for desc in cursor.description]
    rows = [dict(zip(columns, row)) for row in cursor.fetchall()]

    export = {
        "export_timestamp": datetime.now().isoformat(),
        "metrics_count": len(rows),
        "metrics": rows
    }

    with open(output_path, 'w') as f:
        json.dump(export, f, indent=2, default=str)

    logger.info(f"Exported {len(rows)} metrics to {output_path}")
```

**Right to Access (Article 15):**

```bash
# Show user's stored metrics data
$ ragged privacy metrics show
Your Metrics Data:
  Total Queries: 1,247
  Date Range: 2024-08-19 to 2024-11-19 (92 days)
  Average RAGAS: 0.78
  Sessions: 42

  Privacy Status:
    âœ“ Queries stored as hashes (not plaintext)
    âœ“ TTL enabled (90 days)
    âœ“ Session isolation enabled
    âœ“ Auto-cleanup active
```

### Session Isolation (v0.2.10 Integration)

Each session's metrics are isolated:

```python
# Session-scoped metrics
from src.core.session import get_session_manager

def record_session_metrics(
    question: str,
    metrics: Dict[str, float]
) -> None:
    """Record metrics with session isolation (v0.2.10)."""
    session_mgr = get_session_manager()
    current_session = session_mgr.get_current_session()

    db = MetricsDatabase()
    db.record_query(
        question=question,
        answer="",  # Not stored for privacy
        metrics=metrics,
        session_id=current_session.session_id  # âœ… Session-scoped
    )
```

**Benefits:**
- Metrics isolated per session
- Can delete metrics for specific session
- Prevents cross-session analytics leakage

### Privacy Risk Assessment

| Risk | Likelihood | Impact | Mitigation (v0.2.11) |
|------|-----------|--------|---------------------|
| Database contains plaintext queries | NONE | N/A | Queries hashed, not stored |
| Database accessible by others | MEDIUM | HIGH | File permissions 0o600 |
| Metrics persist indefinitely | NONE | N/A | TTL-based auto-deletion (90 days) |
| Cross-session metrics leakage | LOW | MEDIUM | Session isolation (v0.2.10) |
| Database backup exposes PII | LOW | LOW | Only hashes stored, not queries |

**Privacy Score:** 95/100 (Excellent with v0.2.10/v0.2.11)

**Why 95/100 (not 100):**
- SQLite doesn't have native encryption (recommend OS-level encryption)
- Query hashes could theoretically be brute-forced for common queries (mitigated by salted hash)

### Recommendations for Enhanced Privacy

**Optional: SQLCipher Integration (Future)**

For maximum security, consider SQLCipher (encrypted SQLite):

```python
# Future: SQLCipher support
import sqlcipher3 as sqlite3

class EncryptedMetricsDatabase(MetricsDatabase):
    def __init__(self, db_path: Path, encryption_key: bytes):
        self.conn = sqlite3.connect(str(db_path))
        self.conn.execute(f"PRAGMA key = '{encryption_key.hex()}'")
        # Now database is encrypted at rest
```

**Dependencies:** `sqlcipher3` (LGPL, GPL-compatible)
**Benefit:** Database encrypted even if file is copied

### Implementation Checklist

**Privacy Requirements:**
- [ ] Query hashing implemented (no plaintext storage)
- [ ] Database schema excludes PII columns
- [ ] File permissions set to 0o600
- [ ] TTL cleanup registered with v0.2.11 scheduler
- [ ] Session isolation integrated (v0.2.10)
- [ ] GDPR deletion/export implemented
- [ ] Privacy commands implemented (`privacy metrics show`)
- [ ] User control for metrics collection (can disable)
- [ ] Documentation warns about OS-level encryption recommendation

**Testing:**
- [ ] Verify no plaintext queries in database
- [ ] Verify query hashes cannot be reversed
- [ ] Test TTL cleanup removes expired records
- [ ] Test GDPR deletion removes all data
- [ ] Test session isolation (different sessions = different metrics)
- [ ] Test database file permissions are 0o600
- [ ] Verify VACUUM reclaims space after deletion

---

## Implementation Phases

### Phase 1: Design & Architecture (3-4h)

**Sessions 1:**
- Design profiling instrumentation strategy
- Design metrics storage schema
- Plan dashboard layout
- Define quality thresholds

**Deliverables:**
- Profiling architecture documented
- Metrics schema finalized
- Dashboard mockups

### Phase 2: Performance Profiling Implementation (5-7h)

**Sessions 2-3:**
- Implement `Profiler` class
- Add timing decorators to all pipeline stages
- Memory tracking integration
- Bottleneck detection heuristics
- Formatted output (tables)
- CLI integration: `ragged profile`
- Unit tests
- Test on diverse workloads

**Deliverables:**
- Profiling fully functional
- All pipeline stages instrumented
- Tests passing

### Phase 3: Quality Metrics Implementation (6-8h)

**Sessions 4-5:**
- Create SQLite metrics schema
- Implement `MetricsCollector` class
- Hook into query pipeline
- Hook into ingestion pipeline
- RAGAS score aggregation
- Trend analysis
- Dashboard rendering
- Export functionality
- Configuration comparison
- Unit tests
- Integration tests

**Deliverables:**
- Metrics dashboard working
- Historical tracking functional
- Tests passing

### Phase 4: Documentation & Release (2-3h)

**Session 6:**
- Use documentation-architect agent
- Document profiling usage
- Document metrics dashboard
- Create interpretation guides
- Use documentation-auditor agent
- Use git-documentation-committer agent
- Tag v0.3.10 release

**Deliverables:**
- Complete documentation
- Release tagged

---

## Technical Architecture

### Module Structure

```
src/cli/commands/
â”œâ”€â”€ profile.py                  # Performance profiling (250 lines)
â”‚   â””â”€â”€ class Profiler
â””â”€â”€ metrics.py                  # Quality metrics (350 lines)
    â””â”€â”€ class MetricsCollector

src/monitoring/
â”œâ”€â”€ profiler.py                 # Core profiling (200 lines)
â”‚   â””â”€â”€ class PerformanceProfiler
â”œâ”€â”€ metrics_storage.py          # Metrics database (150 lines)
â”‚   â””â”€â”€ class MetricsDB
â””â”€â”€ dashboard.py                # Dashboard rendering (200 lines)

data/
â””â”€â”€ metrics.db                  # SQLite metrics database

tests/monitoring/
â”œâ”€â”€ test_profiler.py
â”œâ”€â”€ test_metrics_storage.py
â””â”€â”€ test_dashboard.py
```

### Profiling Architecture

```python
class Profiler:
    """Performance profiler with timing and memory tracking."""

    def __init__(self):
        self.stages: List[ProfileStage] = []
        self.memory_tracker = MemoryTracker()

    @contextmanager
    def stage(self, name: str):
        """Profile a pipeline stage."""
        start_time = time.perf_counter()
        start_memory = self.memory_tracker.current()

        yield

        duration = time.perf_counter() - start_time
        memory_used = self.memory_tracker.current() - start_memory

        self.stages.append(ProfileStage(
            name=name,
            duration_ms=duration * 1000,
            memory_mb=memory_used / 1024 / 1024
        ))

    def analyse_bottlenecks(self) -> List[str]:
        """Identify bottlenecks and generate recommendations."""
        total_time = sum(s.duration_ms for s in self.stages)
        recommendations = []

        for stage in self.stages:
            percentage = (stage.duration_ms / total_time) * 100
            if percentage > 50:
                recommendations.append(
                    f"âš ï¸  {stage.name} taking {percentage:.1f}% of total time"
                )

        return recommendations

# Usage in query pipeline
def query_with_profiling(question: str, profile: bool = False):
    profiler = Profiler() if profile else None

    if profiler:
        with profiler.stage("Query Preprocessing"):
            preprocessed = preprocess(question)

        with profiler.stage("Query Embedding"):
            embedding = embed(preprocessed)

        # ... more stages

        print(profiler.render())
        print("\nğŸ” Bottleneck Analysis:")
        for rec in profiler.analyse_bottlenecks():
            print(f"  {rec}")

    return answer
```

### Metrics Database Schema

```sql
CREATE TABLE queries (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    question TEXT NOT NULL,
    config_hash TEXT,
    duration_ms REAL,
    chunks_retrieved INTEGER,
    avg_confidence REAL,
    context_precision REAL,
    context_recall REAL,
    faithfulness REAL,
    answer_relevancy REAL,
    ragas_score REAL,
    success BOOLEAN
);

CREATE TABLE ingestions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    document_path TEXT NOT NULL,
    file_size_mb REAL,
    duration_ms REAL,
    chunks_created INTEGER,
    ocr_confidence REAL,
    success BOOLEAN
);

CREATE TABLE config_snapshots (
    config_hash TEXT PRIMARY KEY,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    config_json TEXT NOT NULL
);

CREATE INDEX idx_queries_timestamp ON queries(timestamp);
CREATE INDEX idx_queries_config ON queries(config_hash);
```

### Metrics Collection

```python
class MetricsCollector:
    """Collect and store quality metrics."""

    def __init__(self, db_path: Path):
        self.db = MetricsDB(db_path)

    def record_query(
        self,
        question: str,
        duration_ms: float,
        chunks: List[Chunk],
        answer: str,
        ragas_scores: Dict[str, float],
        config: Dict[str, Any]
    ):
        """Record query metrics."""
        self.db.insert_query(
            question=question,
            config_hash=hash_config(config),
            duration_ms=duration_ms,
            chunks_retrieved=len(chunks),
            avg_confidence=np.mean([c.confidence for c in chunks]),
            **ragas_scores
        )

    def get_dashboard(self, last_n: int = 100) -> Dashboard:
        """Generate metrics dashboard."""
        queries = self.db.get_recent_queries(last_n)

        return Dashboard(
            ragas_stats=self._compute_ragas_stats(queries),
            performance_stats=self._compute_performance_stats(queries),
            trends=self._compute_trends(queries)
        )

    def compare_configs(
        self,
        config1: Dict[str, Any],
        config2: Dict[str, Any]
    ) -> Comparison:
        """Compare metrics for two configurations."""
        hash1 = hash_config(config1)
        hash2 = hash_config(config2)

        metrics1 = self.db.get_metrics_by_config(hash1)
        metrics2 = self.db.get_metrics_by_config(hash2)

        return Comparison(
            config1_metrics=aggregate(metrics1),
            config2_metrics=aggregate(metrics2),
            delta=compute_delta(metrics1, metrics2)
        )
```

---

## Risk Analysis & Mitigation

**Risk 1: Profiling Performance Overhead**
- **Impact:** Medium - Profiling slows down operations
- **Probability:** High - Instrumentation always has overhead
- **Mitigation:** Profiling is opt-in, minimal overhead (<5%), disable in production
- **Detection:** Benchmark with/without profiling

**Risk 2: Metrics Database Growth**
- **Impact:** Medium - Large database over time
- **Probability:** High - Metrics accumulate
- **Mitigation:** Configurable retention policy, aggregation for old data, vacuum command
- **Detection:** Monitor database size

**Risk 3: RAGAS Computation Cost**
- **Impact:** Medium - Expensive to compute for all queries
- **Probability:** Medium - LLM-based evaluation is slow
- **Mitigation:** Sampling (compute for 10% of queries), async computation, caching
- **Detection:** Performance monitoring

**Risk 4: Dashboard Rendering Performance**
- **Impact:** Low - Slow dashboard on large datasets
- **Probability:** Low - SQLite aggregation is fast
- **Mitigation:** Limit queries shown, pagination, caching
- **Detection:** Dashboard load time

---

## Quality Gates

### Functional Requirements
- [ ] Profiling captures all pipeline stages
- [ ] Timing accuracy within 5%
- [ ] Memory tracking works
- [ ] Bottleneck detection identifies slow stages
- [ ] Metrics database stores all events
- [ ] Dashboard displays current metrics
- [ ] Trends show historical data
- [ ] Configuration comparison works
- [ ] Export to JSON/CSV works

### Performance Requirements
- [ ] Profiling overhead <5%
- [ ] Metrics recording <10ms per event
- [ ] Dashboard renders <1s for 1000 queries
- [ ] Export completes <5s for 10,000 records

### Quality Requirements
- [ ] Timing measurements accurate (Â±5%)
- [ ] Memory measurements accurate (Â±10%)
- [ ] RAGAS scores match manual evaluation
- [ ] Dashboard shows correct statistics

### Code Quality Requirements
- [ ] 100% test coverage for new code
- [ ] All tests passing
- [ ] Type hints complete
- [ ] Docstrings complete (British English)

---

## Execution Checklist

### Pre-Implementation
- [ ] Create branch: `git checkout -b feature/v0.3.10-performance-quality-tools`
- [ ] Design profiling architecture
- [ ] Design metrics schema

### Performance Profiling Implementation
- [ ] Add dependency: `memory-profiler>=0.61.0`
- [ ] Create `src/monitoring/profiler.py`
- [ ] Implement `Profiler` class with context managers
- [ ] Add timing decorators
- [ ] Add memory tracking
- [ ] Implement bottleneck detection
- [ ] Formatted output (rich tables)
- [ ] CLI command: `ragged profile`
- [ ] Unit tests
- [ ] Performance testing

### Quality Metrics Implementation
- [ ] Create `src/monitoring/metrics_storage.py`
- [ ] Design SQLite schema
- [ ] Implement `MetricsDB` class
- [ ] Implement `MetricsCollector` class
- [ ] Hook into query pipeline
- [ ] Hook into ingestion pipeline
- [ ] RAGAS score aggregation
- [ ] Trend computation (time-series)
- [ ] Dashboard rendering
- [ ] Configuration comparison
- [ ] Export to JSON/CSV
- [ ] CLI command: `ragged metrics`
- [ ] Unit tests
- [ ] Integration tests

### Testing & Validation
- [ ] Test profiling on all operations
- [ ] Verify timing accuracy
- [ ] Verify memory tracking
- [ ] Test metrics collection
- [ ] Test dashboard rendering
- [ ] Test trend analysis
- [ ] Test configuration comparison
- [ ] Performance testing

### Documentation & Release
- [ ] Use documentation-architect agent
- [ ] Document profiling usage
- [ ] Document metrics dashboard
- [ ] Add interpretation guides
- [ ] Create troubleshooting guide
- [ ] Run documentation-auditor agent
- [ ] Use git-documentation-committer agent
- [ ] Tag v0.3.10 release

---

## Dependencies

```toml
[tool.poetry.dependencies]
memory-profiler = "^0.61.0"   # BSD - Memory usage tracking
rich = "^13.7.0"               # MIT - Beautiful tables and formatting
```

---

## Agent Workflow (6-8h)

1. **documentation-architect (2h):** Profiling and metrics documentation
2. **documentation-auditor (2-3h):** Comprehensive review
3. **git-documentation-committer (2-3h):** Commit

---

## Deliverables

1. **Performance Profiling** - Identify bottlenecks with detailed timing and memory analysis
2. **Quality Metrics Dashboard** - Real-time RAGAS scores and trends
3. **Historical Tracking** - SQLite-based metrics storage
4. **Configuration Comparison** - A/B testing for configurations
5. **Export Functionality** - Metrics export to JSON/CSV

---

## Success Criteria

- âœ… Profiling captures all pipeline stages accurately
- âœ… Bottleneck detection identifies performance issues
- âœ… Metrics dashboard shows current RAGAS scores
- âœ… Historical trends visualised clearly
- âœ… Configuration comparison enables A/B testing
- âœ… Profiling overhead <5%
- âœ… All tests passing, documentation complete

---

## Related Documentation

- [v0.3.0 Roadmap](./README.md) - Overview
- [v0.3.1 - Foundation & Metrics](./v0.3.1.md) - RAGAS baseline
- [v0.3.9 - Developer Experience I](./v0.3.9.md) - Debug mode integration

---

**Status:** Planned
