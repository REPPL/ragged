# v0.3.10 - Automation & Templates

**Category:** CLI - Workflow Automation

**Estimated Time:** 18-24 hours

**Status:** Planned

---

## Overview

Template-based queries and testing tools for repeatable workflows.

**Target Users:** Power users, researchers, developers, QA teams

**Key Innovation:** Jinja2-powered query templates enable complex, repeatable RAG workflows without programming.

---

## Prerequisites

**Security & Privacy Foundation (REQUIRED):**

All v0.3.x versions depend on the security and privacy infrastructure established in v0.2.10 and v0.2.11. These versions MUST be completed before implementing any v0.3.x features.

- âœ… **v0.2.10 (Security Hardening)** - Eliminates Pickle vulnerabilities, implements session isolation, establishes security testing framework
- âœ… **v0.2.11 (Privacy Infrastructure)** - Provides encryption at rest, PII detection/redaction, data lifecycle management, GDPR compliance

**Why Required:** v0.3.x features will store and process user data (metrics, REPL history, API requests). The security and privacy foundations ensure this data is protected from the start.

---

## Features

### CLI-013: Query Templates (5-6h)

**Priority:** High
**Dependencies:** v0.3.0 (configuration system)

#### Scope

Jinja2-based query templating for repeatable, parameterised workflows.

**Use Cases:**
- Research workflows (standardised questions across documents)
- Batch processing (run same query on multiple documents)
- Report generation (template-based summaries)
- Data extraction (structured queries)
- Multi-step workflows (chain queries)

**User Experience:**
```bash
$ cat templates/research_summary.j2
# Research Summary for {{ document }}

## Main Findings
{{ query("What are the main findings in this paper?") }}

## Methodology
{{ query("What methodology was used?") }}

## Limitations
{{ query("What are the limitations?") }}

## Future Work
{{ query("What future work is suggested?") }}

$ ragged template run templates/research_summary.j2 --document "paper.pdf"

# Research Summary for paper.pdf

## Main Findings
The paper presents three key findings:
1. Machine learning models can...
[detailed answer]

## Methodology
The authors employed a mixed-methods approach...
[detailed answer]

## Limitations
The study has several limitations...
[detailed answer]

## Future Work
The authors suggest further research into...
[detailed answer]

$ ragged template run templates/compare_papers.j2 --doc1 "paper1.pdf" --doc2 "paper2.pdf"

# Paper Comparison

## Paper 1 Summary
{{ query("Summarise the main points", document="paper1.pdf") }}

## Paper 2 Summary
{{ query("Summarise the main points", document="paper2.pdf") }}

## Comparison
Based on the above summaries, the key differences are:
{{ query("Compare the methodologies in papers 1 and 2") }}

$ ragged template list
Available templates:
  research_summary.j2       - Structured research paper summary
  compare_papers.j2         - Compare two papers
  extract_data.j2           - Extract structured data
  weekly_report.j2          - Generate weekly summary

$ ragged template create my_template.j2
âœ“ Created template at templates/my_template.j2
```

#### Implementation Overview

- **Module:** `src/cli/commands/template.py`
- **Approach:** Jinja2 templating with custom ragged extensions
- **Libraries:** jinja2, pydantic (validation)
- **Integration:** Full access to query, retrieve, summarise functions

#### Key Components

- `TemplateEngine` class (Jinja2 wrapper)
- Custom Jinja2 filters and functions
- Template validation and linting
- Template library management
- Batch execution support
- Output formatting (markdown, JSON, CSV)

---

### CLI-019: Testing Utilities (5-6h)

**Priority:** Medium
**Dependencies:** v0.3.0 (configuration), v0.3.0 (metrics)

#### Scope

Configuration validation and testing utilities for ensuring quality.

**Use Cases:**
- Validate configurations before deployment
- Test retrieval quality on benchmark datasets
- Regression testing (detect quality drops)
- CI/CD integration
- Configuration auditing

**User Experience:**
```bash
$ ragged test config configs/production.yaml

ðŸ§ª Configuration Validation: production.yaml

Syntax Validation:
  âœ“ Valid YAML syntax
  âœ“ All required fields present
  âœ“ No unknown fields
  âœ“ Type validation passed

Semantic Validation:
  âœ“ Embedding model exists: sentence-transformers/all-MiniLM-L6-v2
  âœ“ LLM model accessible: gpt-3.5-turbo
  âš ï¸  Warning: retrieval.top_k=20 is high (recommended: 5-10)
  âœ“ Chunk sizes within bounds (200-1500)
  âœ“ Persona 'accuracy' exists

Security Check:
  âœ“ No hardcoded API keys
  âœ“ Secure file permissions
  âœ— Error: API key not set in environment (OPENAI_API_KEY)

Recommendation: Fix 1 error, review 1 warning

$ ragged test retrieval --benchmark tests/benchmark_queries.json

ðŸ§ª Retrieval Quality Test

Benchmark: tests/benchmark_queries.json (50 queries)

Running queries... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 50/50

Results:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric                  â”‚ Score  â”‚ Target â”‚ Status â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Context Precision       â”‚ 0.87   â”‚ >0.80  â”‚ âœ… PASS â”‚
â”‚ Context Recall          â”‚ 0.82   â”‚ >0.75  â”‚ âœ… PASS â”‚
â”‚ Faithfulness            â”‚ 0.91   â”‚ >0.85  â”‚ âœ… PASS â”‚
â”‚ Answer Relevancy        â”‚ 0.85   â”‚ >0.80  â”‚ âœ… PASS â”‚
â”‚ Overall RAGAS           â”‚ 0.86   â”‚ >0.80  â”‚ âœ… PASS â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Performance:
  Average query time: 1,234ms
  P95 query time: 2,156ms
  P99 query time: 3,456ms

âœ… All quality gates passed

$ ragged test regression --baseline metrics_v0.3.0.json

ðŸ§ª Regression Test

Comparing current metrics to baseline (v0.3.0)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric                  â”‚ Current  â”‚ Baseline â”‚ Î”      â”‚ Status â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Context Precision       â”‚ 0.87     â”‚ 0.85     â”‚ +0.02  â”‚ âœ… PASS â”‚
â”‚ Context Recall          â”‚ 0.82     â”‚ 0.83     â”‚ -0.01  â”‚ âš ï¸  WARN â”‚
â”‚ Faithfulness            â”‚ 0.91     â”‚ 0.90     â”‚ +0.01  â”‚ âœ… PASS â”‚
â”‚ Answer Relevancy        â”‚ 0.85     â”‚ 0.86     â”‚ -0.01  â”‚ âš ï¸  WARN â”‚
â”‚ Overall RAGAS           â”‚ 0.86     â”‚ 0.86     â”‚ +0.00  â”‚ âœ… PASS â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Regression Threshold: -0.05 (5% drop triggers failure)

âš ï¸  2 warnings: Minor regressions detected but within threshold
âœ… Regression test passed
```

#### Implementation Overview

- **Module:** `src/cli/commands/test.py`
- **Approach:** Validation framework + benchmark execution
- **Libraries:** pydantic (validation), pytest (framework)
- **Integration:** Uses metrics from v0.3.10

#### Key Components

- `ConfigValidator` class
- `BenchmarkRunner` class
- `RegressionTester` class
- Validation rules engine
- Benchmark dataset format (JSON)
- CI/CD integration scripts
- Test report generation

---

## Implementation Phases

### Phase 1: Design & Architecture (3-4h)

**Sessions 1:**
- Design template syntax and functions
- Design validation rules
- Plan benchmark dataset format
- Define quality gates

**Deliverables:**
- Template syntax spec
- Validation rules documented
- Benchmark format defined

### Phase 2: Query Templates Implementation (5-7h)

**Sessions 2-3:**
- Implement `TemplateEngine` class
- Add Jinja2 custom functions (query, retrieve, summarise)
- Add custom filters
- Template validation and linting
- Template library management
- Batch execution
- Output formatting
- CLI integration: `ragged template`
- Unit tests
- Example templates

**Deliverables:**
- Template engine functional
- Example templates created
- Tests passing

### Phase 3: Testing Utilities Implementation (5-7h)

**Sessions 4-5:**
- Implement `ConfigValidator` class
- Add validation rules
- Implement `BenchmarkRunner` class
- Implement `RegressionTester` class
- Benchmark dataset loading
- Test reporting
- CLI integration: `ragged test`
- Unit tests
- Integration tests

**Deliverables:**
- Testing utilities functional
- Validation working
- Tests passing

### Phase 4: Documentation & Release (2-3h)

**Session 6:**
- Use documentation-architect agent
- Document template syntax
- Document testing utilities
- Create template examples
- Create benchmark examples
- Use documentation-auditor agent
- Use git-documentation-committer agent
- Tag v0.3.10 release

**Deliverables:**
- Complete documentation
- Release tagged

---

## Technical Architecture

### Module Structure

```
src/cli/commands/
â”œâ”€â”€ template.py                 # Template commands (250 lines)
â”‚   â””â”€â”€ class TemplateEngine
â””â”€â”€ test.py                     # Testing commands (300 lines)

src/templates/
â”œâ”€â”€ engine.py                   # Jinja2 engine (200 lines)
â”‚   â””â”€â”€ class TemplateEngine
â”œâ”€â”€ functions.py                # Custom functions (150 lines)
â””â”€â”€ filters.py                  # Custom filters (100 lines)

src/testing/
â”œâ”€â”€ config_validator.py         # Config validation (200 lines)
â”‚   â””â”€â”€ class ConfigValidator
â”œâ”€â”€ benchmark_runner.py         # Benchmark execution (250 lines)
â”‚   â””â”€â”€ class BenchmarkRunner
â””â”€â”€ regression_tester.py        # Regression testing (150 lines)
    â””â”€â”€ class RegressionTester

templates/                      # Built-in templates
â”œâ”€â”€ research_summary.j2
â”œâ”€â”€ compare_papers.j2
â”œâ”€â”€ extract_data.j2
â””â”€â”€ weekly_report.j2

tests/
â”œâ”€â”€ test_template_engine.py
â”œâ”€â”€ test_config_validator.py
â”œâ”€â”€ test_benchmark_runner.py
â””â”€â”€ benchmark_queries.json      # Example benchmark
```

### Template Engine Architecture

```python
class TemplateEngine:
    """Jinja2-based query templating."""

    def __init__(self, ragged_client):
        self.client = ragged_client
        self.env = self._create_jinja_env()

    def _create_jinja_env(self) -> jinja2.Environment:
        """Create Jinja2 environment with custom functions."""
        env = jinja2.Environment(
            loader=jinja2.FileSystemLoader("templates"),
            autoescape=False
        )

        # Add custom functions
        env.globals['query'] = self._query_function
        env.globals['retrieve'] = self._retrieve_function
        env.globals['summarise'] = self._summarise_function

        # Add custom filters
        env.filters['markdown'] = self._markdown_filter
        env.filters['chunk_text'] = self._chunk_text_filter

        return env

    def _query_function(
        self,
        question: str,
        document: Optional[str] = None,
        **kwargs
    ) -> str:
        """Execute a query within template."""
        return self.client.query(
            question=question,
            filters={"document": document} if document else {},
            **kwargs
        )

    def render(
        self,
        template_path: Path,
        variables: Dict[str, Any]
    ) -> str:
        """Render template with variables."""
        template = self.env.get_template(str(template_path))
        return template.render(**variables)

# Example template usage
template_content = """
# Summary for {{ document }}

## Overview
{{ query("Provide a one-paragraph overview", document=document) }}

## Key Points
{% for topic in topics %}
### {{ topic }}
{{ query("What does the paper say about " + topic, document=document) }}
{% endfor %}
"""
```

### Configuration Validator

```python
class ConfigValidator:
    """Validate ragged configuration files."""

    def __init__(self):
        self.rules = self._load_rules()

    def validate(self, config_path: Path) -> ValidationResult:
        """Validate configuration file."""
        # 1. Syntax validation
        syntax_errors = self._validate_syntax(config_path)
        if syntax_errors:
            return ValidationResult(errors=syntax_errors)

        config = self._load_config(config_path)

        # 2. Schema validation
        schema_errors = self._validate_schema(config)

        # 3. Semantic validation
        semantic_warnings = self._validate_semantics(config)

        # 4. Security validation
        security_errors = self._validate_security(config)

        return ValidationResult(
            errors=schema_errors + security_errors,
            warnings=semantic_warnings
        )

    def _validate_schema(self, config: Dict) -> List[str]:
        """Validate against schema."""
        # Use pydantic model for validation
        try:
            ConfigModel(**config)
            return []
        except ValidationError as e:
            return [str(err) for err in e.errors()]

    def _validate_semantics(self, config: Dict) -> List[str]:
        """Semantic validation (best practices)."""
        warnings = []

        # Check retrieval.top_k
        top_k = config.get("retrieval", {}).get("top_k", 5)
        if top_k > 10:
            warnings.append(
                f"retrieval.top_k={top_k} is high (recommended: 5-10)"
            )

        # Check chunk sizes
        chunk_size = config.get("chunking", {}).get("chunk_size", 500)
        if chunk_size > 1500:
            warnings.append(
                f"chunking.chunk_size={chunk_size} may be too large"
            )

        return warnings

    def _validate_security(self, config: Dict) -> List[str]:
        """Security validation."""
        errors = []

        # Check for hardcoded API keys
        config_str = json.dumps(config)
        if "sk-" in config_str:
            errors.append("Potential hardcoded API key detected")

        # Check environment variables
        required_env_vars = ["OPENAI_API_KEY"]
        for var in required_env_vars:
            if not os.getenv(var):
                errors.append(f"Required environment variable not set: {var}")

        return errors
```

### Benchmark Dataset Format

```json
{
  "name": "Research Paper Q&A Benchmark",
  "version": "1.0",
  "created": "2024-01-15",
  "queries": [
    {
      "id": "q001",
      "question": "What are the main findings?",
      "expected_keywords": ["machine learning", "accuracy", "improvement"],
      "expected_documents": ["paper1.pdf"],
      "ground_truth_answer": "The main findings include...",
      "quality_thresholds": {
        "context_precision": 0.85,
        "context_recall": 0.80,
        "faithfulness": 0.90,
        "answer_relevancy": 0.85
      }
    },
    {
      "id": "q002",
      "question": "What methodology was used?",
      "expected_keywords": ["mixed-methods", "qualitative", "quantitative"],
      "expected_documents": ["paper1.pdf"],
      "ground_truth_answer": null,
      "quality_thresholds": {
        "context_precision": 0.80,
        "context_recall": 0.75,
        "faithfulness": 0.85,
        "answer_relevancy": 0.80
      }
    }
  ]
}
```

---

## Risk Analysis & Mitigation

**Risk 1: Template Injection Attacks**
- **Impact:** High - Malicious templates could execute arbitrary code
- **Probability:** Low - Templates are user-created, not external
- **Mitigation:** Sandbox Jinja2 environment, disable unsafe features, template validation
- **Detection:** Security audits, code review

**Risk 2: Template Complexity**
- **Impact:** Medium - Complex templates hard to debug
- **Probability:** Medium - Users may create complex workflows
- **Mitigation:** Template validation, error messages, debugging mode, examples
- **Detection:** User feedback, support requests

**Risk 3: Benchmark Dataset Quality**
- **Impact:** Medium - Poor benchmarks give false confidence
- **Probability:** Medium - Creating good benchmarks is hard
- **Mitigation:** Provide curated benchmarks, validation, documentation on best practices
- **Detection:** Manual review, community feedback

**Risk 4: Configuration Validation False Positives**
- **Impact:** Low - Valid configs rejected
- **Probability:** Low - Validation rules well-tested
- **Mitigation:** Conservative validation, warnings vs errors, override flags
- **Detection:** User reports, testing

---

## Quality Gates

### Functional Requirements
- [ ] Template engine renders templates correctly
- [ ] Custom Jinja2 functions work (query, retrieve, summarise)
- [ ] Template validation detects syntax errors
- [ ] Batch execution works
- [ ] Configuration validation detects errors
- [ ] Semantic validation provides helpful warnings
- [ ] Security validation detects API keys
- [ ] Benchmark runner executes queries
- [ ] Regression tester compares metrics
- [ ] Test reports generated correctly

### Performance Requirements
- [ ] Template rendering <100ms for simple templates
- [ ] Configuration validation <500ms
- [ ] Benchmark execution time proportional to query count
- [ ] Regression testing <5s

### UX Requirements
- [ ] Template syntax intuitive
- [ ] Error messages helpful
- [ ] Example templates provided
- [ ] Documentation clear
- [ ] Test reports readable

### Code Quality Requirements
- [ ] 100% test coverage for new code
- [ ] All tests passing
- [ ] Type hints complete
- [ ] Docstrings complete (British English)

---

## Execution Checklist

### Pre-Implementation
- [ ] Create branch: `git checkout -b feature/v0.3.10-automation-templates`
- [ ] Design template syntax
- [ ] Design validation rules
- [ ] Define benchmark format

### Query Templates Implementation
- [ ] Add dependency: `jinja2>=3.1.0`
- [ ] Create `src/templates/engine.py`
- [ ] Implement `TemplateEngine` class
- [ ] Add custom Jinja2 functions (query, retrieve, summarise)
- [ ] Add custom filters
- [ ] Template validation
- [ ] Template library management
- [ ] Batch execution
- [ ] Output formatting (markdown, JSON, CSV)
- [ ] CLI command: `ragged template`
- [ ] Create example templates
- [ ] Unit tests

### Testing Utilities Implementation
- [ ] Create `src/testing/config_validator.py`
- [ ] Implement `ConfigValidator` class
- [ ] Add validation rules
- [ ] Syntax validation
- [ ] Schema validation (pydantic)
- [ ] Semantic validation
- [ ] Security validation
- [ ] Create `src/testing/benchmark_runner.py`
- [ ] Implement `BenchmarkRunner` class
- [ ] Benchmark dataset loading
- [ ] Query execution and scoring
- [ ] Create `src/testing/regression_tester.py`
- [ ] Implement `RegressionTester` class
- [ ] Baseline comparison
- [ ] CLI command: `ragged test`
- [ ] Create example benchmark
- [ ] Unit tests
- [ ] Integration tests

### Testing & Validation
- [ ] Test template rendering
- [ ] Test custom functions
- [ ] Test configuration validation
- [ ] Test benchmark execution
- [ ] Test regression detection
- [ ] Performance testing
- [ ] Security testing (template injection)

### Documentation & Release
- [ ] Use documentation-architect agent
- [ ] Document template syntax
- [ ] Document custom functions and filters
- [ ] Document testing utilities
- [ ] Create template examples
- [ ] Create benchmark examples
- [ ] CI/CD integration guide
- [ ] Run documentation-auditor agent
- [ ] Use git-documentation-committer agent
- [ ] Tag v0.3.10 release

---

## Dependencies

```toml
[tool.poetry.dependencies]
jinja2 = "^3.1.0"              # BSD - Template engine
pydantic = "^2.5.0"            # MIT - Validation (already in dependencies)
```

---

## Agent Workflow (6-8h)

1. **documentation-architect (2h):** Template and testing documentation
2. **documentation-auditor (2-3h):** Comprehensive review
3. **git-documentation-committer (2-3h):** Commit

---

## Deliverables

1. **Query Templates** - Jinja2-powered repeatable workflows
2. **Configuration Validation** - Syntax, semantic, and security checks
3. **Benchmark Testing** - Quality assurance on test datasets
4. **Regression Testing** - Detect quality drops between versions
5. **Example Templates** - Research, comparison, extraction workflows
6. **CI/CD Integration** - Automated testing support

---

## Success Criteria

- âœ… Template engine renders complex workflows correctly
- âœ… Configuration validation catches errors and provides helpful warnings
- âœ… Benchmark testing validates retrieval quality
- âœ… Regression testing detects quality drops
- âœ… Example templates demonstrate capabilities
- âœ… Security validation prevents template injection
- âœ… All tests passing, documentation complete

---

## Related Documentation

- [v0.3.0 Roadmap](./README.md) - Overview
- [v0.3.0 - Configuration Transparency](./v0.3.0.md) - Configuration system foundation
- [v0.3.0 - Performance & Quality Tools](./v0.3.0.md) - Metrics integration

---

**Status:** Planned
