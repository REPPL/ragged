# v0.3.12 - Production Operations

**Category:** CLI - Production Monitoring

**Estimated Time:** 17-23 hours

**Status:** Planned

---

## Overview

Production monitoring and automation for continuous operation.

**Target Users:** System administrators, DevOps, power users, production deployments

**Key Innovation:** Watch mode and scheduled operations enable ragged to operate as a production service, automatically ingesting and processing documents.

---

## Prerequisites

**Security & Privacy Foundation (REQUIRED):**

All v0.3.x versions depend on the security and privacy infrastructure established in v0.2.10 and v0.2.11. These versions MUST be completed before implementing any v0.3.x features.

- âœ… **v0.2.10 (Security Hardening)** - Eliminates Pickle vulnerabilities, implements session isolation, establishes security testing framework
- âœ… **v0.2.11 (Privacy Infrastructure)** - Provides encryption at rest, PII detection/redaction, data lifecycle management, GDPR compliance

**Why Required:** v0.3.x features will store and process user data (metrics, REPL history, API requests). The security and privacy foundations ensure this data is protected from the start.

---

## Features

### CLI-016: Watch Mode (4-5h)

**Priority:** High
**Dependencies:** None

#### Scope

Automatic document ingestion for directories, enabling continuous operation.

**Use Cases:**
- Research teams with shared document folders
- Automated document processing pipelines
- Production deployments with incoming documents
- Dropbox/Google Drive integration
- Network share monitoring

**User Experience:**
```bash
$ ragged watch ~/Documents/Research --pattern "*.pdf"

ðŸ‘ï¸  Watching: /Users/alice/Documents/Research
Patterns: *.pdf
Polling interval: 30s

Press Ctrl+C to stop

[2024-01-15 14:30:15] Detected new file: paper_2024.pdf
[2024-01-15 14:30:15] Processing paper_2024.pdf...
[2024-01-15 14:30:18] âœ“ Added paper_2024.pdf with 127 chunks (98% confidence)

[2024-01-15 14:35:42] Detected new file: thesis_draft.pdf
[2024-01-15 14:35:42] Processing thesis_draft.pdf...
[2024-01-15 14:35:56] âœ“ Added thesis_draft.pdf with 842 chunks (95% confidence)

[2024-01-15 14:40:03] Detected modified file: paper_2024.pdf
[2024-01-15 14:40:03] Reprocessing paper_2024.pdf...
[2024-01-15 14:40:06] âœ“ Updated paper_2024.pdf with 127 chunks (98% confidence)

$ ragged watch ~/Documents/Research --pattern "*.{pdf,docx,txt}" --daemon

âœ“ Watch daemon started (PID: 12345)
  Watching: /Users/alice/Documents/Research
  Patterns: *.pdf, *.docx, *.txt
  Log file: ~/.ragged/watch.log

$ ragged watch stop

âœ“ Watch daemon stopped (PID: 12345)

$ ragged watch status

ðŸ“Š Watch Status

Active watches: 1

[1] /Users/alice/Documents/Research
    Patterns: *.pdf, *.docx, *.txt
    Started: 2024-01-15 14:30:00
    Processed: 47 files
    Errors: 2 files
    Last activity: 2 minutes ago
    PID: 12345
```

#### Implementation Overview

- **Module:** `src/cli/commands/watch.py`
- **Approach:** File system monitoring with watchdog library
- **Libraries:** watchdog (file system events), APScheduler (polling)
- **Integration:** Triggers document ingestion on file events

#### Key Components

- `WatchManager` class (manages watch instances)
- File system event handlers
- Polling mechanism (for network shares)
- Daemon mode support
- Event queue and batching
- Error handling and retry logic
- Log rotation

---

### CLI-017: Scheduled Operations (5-6h)

**Priority:** Medium
**Dependencies:** v0.3.11 (templates)

#### Scope

Cron-like scheduling for automated ragged operations.

**Use Cases:**
- Daily summary reports
- Weekly document processing
- Scheduled quality checks
- Automated backups
- Periodic RAGAS evaluation

**User Experience:**
```bash
$ ragged schedule add daily-summary \
  --cron "0 9 * * *" \
  --command "template run templates/daily_summary.j2"

âœ“ Scheduled: daily-summary
  Schedule: Every day at 09:00
  Command: template run templates/daily_summary.j2
  Next run: 2024-01-16 09:00:00

$ ragged schedule add weekly-quality-check \
  --cron "0 18 * * 5" \
  --command "test retrieval --benchmark tests/benchmark.json"

âœ“ Scheduled: weekly-quality-check
  Schedule: Every Friday at 18:00
  Command: test retrieval --benchmark tests/benchmark.json
  Next run: 2024-01-19 18:00:00

$ ragged schedule list

ðŸ“… Scheduled Operations

[1] daily-summary
    Schedule: Every day at 09:00 (0 9 * * *)
    Command: template run templates/daily_summary.j2
    Status: Active
    Last run: 2024-01-15 09:00:05 (âœ“ Success)
    Next run: 2024-01-16 09:00:00
    Executions: 47

[2] weekly-quality-check
    Schedule: Every Friday at 18:00 (0 18 * * 5)
    Command: test retrieval --benchmark tests/benchmark.json
    Status: Active
    Last run: 2024-01-12 18:00:12 (âœ“ Success)
    Next run: 2024-01-19 18:00:00
    Executions: 12

$ ragged schedule run daily-summary --now

Running: daily-summary (manual execution)

[... execution output ...]

âœ“ Completed successfully

$ ragged schedule disable weekly-quality-check

âœ“ Disabled: weekly-quality-check

$ ragged schedule logs daily-summary --tail 50

ðŸ“œ Execution Logs: daily-summary (last 50 runs)

[2024-01-15 09:00:05] âœ“ Success (duration: 234ms)
[2024-01-14 09:00:03] âœ“ Success (duration: 245ms)
[2024-01-13 09:00:04] âœ— Error: Template not found
[2024-01-12 09:00:06] âœ“ Success (duration: 239ms)
...
```

#### Implementation Overview

- **Module:** `src/cli/commands/schedule.py`
- **Approach:** APScheduler for cron-like scheduling
- **Libraries:** APScheduler, croniter (cron parsing)
- **Storage:** SQLite for schedule persistence

#### Key Components

- `ScheduleManager` class
- Cron expression parser
- Job execution engine
- Execution history tracking
- Email/webhook notifications (optional)
- Schedule persistence (SQLite)
- Background daemon

---

## Implementation Phases

### Phase 1: Design & Architecture (3-4h)

**Sessions 1:**
- Design watch mode architecture
- Design scheduling system
- Plan daemon mode implementation
- Define event handling

**Deliverables:**
- Architecture documented
- Event flow designed
- Schedule persistence schema

### Phase 2: Watch Mode Implementation (4-6h)

**Sessions 2-3:**
- Implement `WatchManager` class
- File system event handlers (watchdog)
- Polling mechanism for network shares
- Event queue and batching
- Daemon mode support
- Error handling and retry
- CLI integration: `ragged watch`
- Unit tests
- Test on diverse scenarios

**Deliverables:**
- Watch mode functional
- Daemon mode working
- Tests passing

### Phase 3: Scheduled Operations Implementation (5-7h)

**Sessions 4-5:**
- Implement `ScheduleManager` class
- Cron parser integration
- Job execution engine
- SQLite persistence
- Execution history tracking
- Notifications (optional)
- CLI integration: `ragged schedule`
- Unit tests
- Integration tests

**Deliverables:**
- Scheduling functional
- Jobs execute on schedule
- Tests passing

### Phase 4: Documentation & Release (2-3h)

**Session 6:**
- Use documentation-architect agent
- Document watch mode
- Document scheduling
- Create production deployment guide
- Use documentation-auditor agent
- Use git-documentation-committer agent
- Tag v0.3.12 release

**Deliverables:**
- Complete documentation
- Release tagged

---

## Technical Architecture

### Module Structure

```
src/cli/commands/
â”œâ”€â”€ watch.py                    # Watch commands (250 lines)
â”‚   â””â”€â”€ class WatchManager
â””â”€â”€ schedule.py                 # Schedule commands (300 lines)
    â””â”€â”€ class ScheduleManager

src/automation/
â”œâ”€â”€ watcher.py                  # File watching (300 lines)
â”‚   â”œâ”€â”€ class FileWatcher
â”‚   â””â”€â”€ class EventHandler
â”œâ”€â”€ scheduler.py                # Job scheduling (250 lines)
â”‚   â””â”€â”€ class JobScheduler
â””â”€â”€ daemon.py                   # Daemon support (150 lines)
    â””â”€â”€ class DaemonManager

data/
â”œâ”€â”€ watch.db                    # Watch state database
â””â”€â”€ schedule.db                 # Schedule database

tests/automation/
â”œâ”€â”€ test_watcher.py
â”œâ”€â”€ test_scheduler.py
â””â”€â”€ test_daemon.py
```

### Watch Mode Architecture

```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class FileWatcher:
    """Monitor directory for file changes."""

    def __init__(
        self,
        path: Path,
        patterns: List[str],
        callback: Callable,
        polling_interval: int = 30
    ):
        self.path = path
        self.patterns = patterns
        self.callback = callback
        self.polling_interval = polling_interval
        self.observer = Observer()

    def start(self):
        """Start watching directory."""
        event_handler = RaggedEventHandler(
            patterns=self.patterns,
            callback=self.callback
        )
        self.observer.schedule(event_handler, str(self.path), recursive=True)
        self.observer.start()

    def stop(self):
        """Stop watching directory."""
        self.observer.stop()
        self.observer.join()

class RaggedEventHandler(FileSystemEventHandler):
    """Handle file system events."""

    def __init__(self, patterns: List[str], callback: Callable):
        self.patterns = patterns
        self.callback = callback
        self.event_queue: Queue = Queue()
        self.processing_thread = Thread(target=self._process_queue)
        self.processing_thread.start()

    def on_created(self, event):
        """Handle file creation."""
        if event.is_directory:
            return

        if self._matches_patterns(event.src_path):
            logger.info(f"Detected new file: {event.src_path}")
            self.event_queue.put(('created', event.src_path))

    def on_modified(self, event):
        """Handle file modification."""
        if event.is_directory:
            return

        if self._matches_patterns(event.src_path):
            logger.info(f"Detected modified file: {event.src_path}")
            self.event_queue.put(('modified', event.src_path))

    def _process_queue(self):
        """Process queued events."""
        while True:
            try:
                event_type, file_path = self.event_queue.get(timeout=1)

                # Debouncing: wait for file to stabilise
                time.sleep(2)

                # Call ingestion callback
                self.callback(file_path, event_type)

            except Empty:
                continue

    def _matches_patterns(self, path: str) -> bool:
        """Check if path matches any pattern."""
        from fnmatch import fnmatch
        return any(fnmatch(path, p) for p in self.patterns)

# Usage
def ingest_callback(file_path: str, event_type: str):
    """Callback for file events."""
    if event_type == 'created':
        ragged_client.add(file_path)
    elif event_type == 'modified':
        ragged_client.update(file_path)

watcher = FileWatcher(
    path=Path("~/Documents/Research"),
    patterns=["*.pdf", "*.docx"],
    callback=ingest_callback
)
watcher.start()
```

### Scheduler Architecture

```python
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger

class JobScheduler:
    """Manage scheduled ragged operations."""

    def __init__(self, db_path: Path):
        self.db = ScheduleDB(db_path)
        self.scheduler = BackgroundScheduler()
        self.scheduler.start()

    def add_job(
        self,
        job_id: str,
        cron: str,
        command: str,
        enabled: bool = True
    ):
        """Add scheduled job."""
        # Store in database
        self.db.insert_job(
            job_id=job_id,
            cron=cron,
            command=command,
            enabled=enabled
        )

        # Add to scheduler
        if enabled:
            self.scheduler.add_job(
                func=self._execute_job,
                args=[job_id, command],
                trigger=CronTrigger.from_crontab(cron),
                id=job_id
            )

    def _execute_job(self, job_id: str, command: str):
        """Execute scheduled job."""
        start_time = time.time()

        try:
            # Execute ragged command
            result = subprocess.run(
                f"ragged {command}",
                shell=True,
                capture_output=True,
                text=True
            )

            duration_ms = (time.time() - start_time) * 1000
            success = result.returncode == 0

            # Record execution
            self.db.record_execution(
                job_id=job_id,
                success=success,
                duration_ms=duration_ms,
                output=result.stdout,
                error=result.stderr
            )

            if success:
                logger.info(f"Job {job_id} completed successfully")
            else:
                logger.error(f"Job {job_id} failed: {result.stderr}")

        except Exception as e:
            logger.error(f"Job {job_id} crashed: {e}")
            self.db.record_execution(
                job_id=job_id,
                success=False,
                error=str(e)
            )

    def list_jobs(self) -> List[Dict]:
        """List all scheduled jobs."""
        jobs = self.db.get_all_jobs()
        for job in jobs:
            # Add next run time from scheduler
            if job['enabled']:
                apsjob = self.scheduler.get_job(job['job_id'])
                job['next_run'] = apsjob.next_run_time if apsjob else None
        return jobs
```

### Schedule Database Schema

```sql
CREATE TABLE jobs (
    job_id TEXT PRIMARY KEY,
    cron TEXT NOT NULL,
    command TEXT NOT NULL,
    enabled BOOLEAN DEFAULT TRUE,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE executions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    job_id TEXT NOT NULL,
    executed_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    success BOOLEAN,
    duration_ms REAL,
    output TEXT,
    error TEXT,
    FOREIGN KEY (job_id) REFERENCES jobs(job_id)
);

CREATE INDEX idx_executions_job_id ON executions(job_id);
CREATE INDEX idx_executions_time ON executions(executed_at);
```

---

## Risk Analysis & Mitigation

**Risk 1: Watch Mode Resource Usage**
- **Impact:** Medium - CPU/memory usage from file monitoring
- **Probability:** Medium - Depends on directory size
- **Mitigation:** Polling interval configuration, event batching, resource limits
- **Detection:** Resource monitoring

**Risk 2: Network Share Reliability**
- **Impact:** Medium - Network issues disrupt watching
- **Probability:** High - Network shares have latency/reliability issues
- **Mitigation:** Polling fallback, error handling, retry logic, health checks
- **Detection:** Connection monitoring, logs

**Risk 3: Scheduled Job Failures**
- **Impact:** Medium - Missed operations
- **Probability:** Medium - Jobs can fail
- **Mitigation:** Execution history, retry logic, notifications, manual override
- **Detection:** Execution logs, monitoring

**Risk 4: Daemon Process Management**
- **Impact:** Low - Daemon crashes or hangs
- **Probability:** Low - Background processes generally stable
- **Mitigation:** Process monitoring, auto-restart, health checks, proper shutdown
- **Detection:** PID tracking, health endpoints

---

## Quality Gates

### Functional Requirements
- [ ] Watch mode detects new files correctly
- [ ] Watch mode detects modified files
- [ ] Watch mode ignores irrelevant files (patterns)
- [ ] Watch mode processes events in order
- [ ] Daemon mode starts and stops cleanly
- [ ] Scheduled jobs execute on time
- [ ] Cron expressions parsed correctly
- [ ] Execution history recorded
- [ ] Manual job execution works
- [ ] Job enable/disable works

### Performance Requirements
- [ ] Watch mode CPU usage <5%
- [ ] Watch mode memory usage <100MB
- [ ] Event processing latency <5s
- [ ] Scheduled job startup <1s

### Reliability Requirements
- [ ] Watch mode recovers from errors
- [ ] Network share polling works
- [ ] Daemon survives system sleep/wake
- [ ] Scheduled jobs retry on failure

### Code Quality Requirements
- [ ] 100% test coverage for new code
- [ ] All tests passing
- [ ] Type hints complete
- [ ] Docstrings complete (British English)

---

## Execution Checklist

### Pre-Implementation
- [ ] Create branch: `git checkout -b feature/v0.3.12-production-operations`
- [ ] Design watch architecture
- [ ] Design scheduling architecture

### Watch Mode Implementation
- [ ] Add dependencies: `watchdog>=3.0.0`
- [ ] Create `src/automation/watcher.py`
- [ ] Implement `FileWatcher` class
- [ ] Implement `EventHandler` class
- [ ] Event queue and batching
- [ ] Polling fallback for network shares
- [ ] Daemon mode support
- [ ] CLI integration: `ragged watch`
- [ ] Unit tests
- [ ] Integration tests (temporary directory)

### Scheduled Operations Implementation
- [ ] Add dependencies: `APScheduler>=3.10.0`, `croniter>=2.0.0`
- [ ] Create `src/automation/scheduler.py`
- [ ] Implement `JobScheduler` class
- [ ] Cron parser integration
- [ ] Job execution engine
- [ ] SQLite persistence
- [ ] Execution history
- [ ] CLI integration: `ragged schedule`
- [ ] Unit tests
- [ ] Integration tests

### Daemon Support
- [ ] Create `src/automation/daemon.py`
- [ ] Implement `DaemonManager` class
- [ ] PID file management
- [ ] Clean shutdown handling
- [ ] Health check endpoint
- [ ] Unit tests

### Testing & Validation
- [ ] Test watch mode on local directories
- [ ] Test watch mode on network shares
- [ ] Test daemon start/stop
- [ ] Test scheduled execution
- [ ] Test cron parsing
- [ ] Test execution history
- [ ] Performance testing (resource usage)
- [ ] Reliability testing (error recovery)

### Documentation & Release
- [ ] Use documentation-architect agent
- [ ] Document watch mode
- [ ] Document scheduling
- [ ] Create production deployment guide
- [ ] Add systemd/launchd service examples
- [ ] Run documentation-auditor agent
- [ ] Use git-documentation-committer agent
- [ ] Tag v0.3.12 release

---

## Dependencies

```toml
[tool.poetry.dependencies]
watchdog = "^3.0.0"            # Apache 2.0 - File system monitoring
APScheduler = "^3.10.0"        # MIT - Job scheduling
croniter = "^2.0.0"            # MIT - Cron parsing
```

---

## Agent Workflow (6-8h)

1. **documentation-architect (2h):** Watch and scheduling documentation
2. **documentation-auditor (2-3h):** Comprehensive review
3. **git-documentation-committer (2-3h):** Commit

---

## Deliverables

1. **Watch Mode** - Automatic directory monitoring and ingestion
2. **Daemon Support** - Background operation with clean shutdown
3. **Scheduled Operations** - Cron-like job scheduling
4. **Execution History** - Track job runs and failures
5. **Production Deployment Guide** - systemd/launchd examples

---

## Success Criteria

- âœ… Watch mode monitors directories reliably
- âœ… File events processed correctly
- âœ… Daemon mode operates stably
- âœ… Scheduled jobs execute on time
- âœ… Execution history tracked
- âœ… Resource usage acceptable (<5% CPU, <100MB RAM)
- âœ… Error recovery works
- âœ… All tests passing, documentation complete

---

## Related Documentation

- [v0.3.0 Roadmap](./README.md) - Overview
- [v0.3.11 - Automation & Templates](./v0.3.11.md) - Template integration for scheduled reports

---

**Status:** Planned
